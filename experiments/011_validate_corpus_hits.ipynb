{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf0d94b-5119-4713-92b7-d726ae9cb270",
   "metadata": {},
   "source": [
    "# Exp011: Corpus Rule Detection\n",
    "For a good external validation, each rule is searched for in the corpus and marked if there is at least 80% precision among the hits. If there are less than 5 hits in the first ten examples, the rule is skipped, otherwise 10 more appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0f9f6b-3536-4c55-80d0-df8520b5cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import save, load, no_grad\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../source')\n",
    "import models\n",
    "import data\n",
    "import helpers\n",
    "import api\n",
    "import importlib\n",
    "#importlib.reload(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b888610-eb83-4e5a-a79c-2f6b11aaec75",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08325525-b773-42e4-a3dc-67db757718c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:32<00:00, 10.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# egp instances\n",
    "egp_examples = pd.read_json(\"../data/egp_examples.json\")\n",
    "# load corpus sentences and prepare dataloader\n",
    "sentences = data.get_mixed_sentences(20000)\n",
    "encoded_inputs = models.bert_tokenizer(sentences, return_tensors='pt', max_length=64, padding='max_length', truncation=True)\n",
    "dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'])\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "# output dataset\n",
    "output_path = '../data/coded_corpus_hits.json'\n",
    "coded_instances = pd.DataFrame(columns=['#', 'sentence', 'correct', 'score', 'max_token']) if not os.path.exists(output_path) else pd.read_json(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94750f-5dae-4d78-83bc-98930feead08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "for each rule:\n",
    "- train classifier with existing dataset\n",
    "- search corpus\n",
    "- output rule to user\n",
    "- ask for user input until the precision is clear enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcd39b8c-16f1-468a-900d-801c7b29c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_classifer(positive, negative, others, classifier=models.RuleDetector(models.bert_encoder), num_epochs=3):\n",
    "    dataset = data.get_dataset(positive, negative, others, models.bert_tokenizer, 64, random_negatives=len(others)>0) \n",
    "    train_dataloader, val_dataloader = data.get_loaders(dataset)\n",
    "    models.train(classifier, train_dataloader, val_dataloader, num_epochs)\n",
    "    return classifier\n",
    "def get_others(egp, nr):\n",
    "    return [example for sublist in egp.loc[egp['#'] != nr, 'augmented_examples'].to_list() for example in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7b6a1c-76b5-4192-bda0-b062e1bbd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(coded_instances, min_precision=0.8, num_rules=1):\n",
    "    correct_per_rule = coded_instances.groupby('#')['correct'].mean()\n",
    "    return len(correct_per_rule[correct_per_rule > min_precision]) > num_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfa855bc-52d6-4b51-b6d9-e6970c52a05b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORM/USE: Can use the negative question form as a persuasion strategy. (PRESENT: present simple)\n",
      "Don't you just hate taking the bus to school every morning? well I have a perfect solution for you, a great bike with good brakes, a bell and lights. it is a great bike but since I never use it I would be happy to sell it to you. \n",
      "\n",
      "Don't you find that when you are having a shower or bath, you occasionally run out of water?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3339063185453415\n",
      "Accuracy: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.08209181800484658\n",
      "Accuracy: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03029802121222019\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████████████████████████▌                                                                        | 574/1250 [00:48<00:57, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Alcohol, don't you think alcohol is not ideal to take as brunch? 2\n",
      "But don't you think it looks rather unfashionable? 2\n",
      "Don't you think that would be a little weird? 2\n",
      "But don't you hate it when you step on something sharp? 2\n",
      "We eat a lot of chicken, pork and beef.You eat those meat a lot in your country too, don't you? 1\n",
      "Don't you know they've already broken up? 1\n",
      "I think Shanghai is getting more and more expensive, don't you? 1\n",
      "I think Shanghai is getting more and more expensive, don't you? 1\n",
      "Don't you know that umbrella is expensive? 2\n",
      "Tom Cruise may be handsome, but I think he's a bit crazy, don't you? 1\n",
      "Yes, I am kidding.But don't you know only professors and students with disabilitiescan apply for parking permits? 1\n",
      "\"Don't you have to be a good bowler to bowl in a league?\" 1\n",
      "Well, don't you? 1\n",
      "You eat those meat a lot in your country too, don't you? 1\n",
      "You eat those meat a lot in your country too, don't you? 1\n",
      "Don't you tell me you speak Spanish, too? 1\n",
      "You do know all the controls in the car, don't you? 1\n",
      "But don't you like this place? 2\n",
      "Don't you like your present job? 1\n",
      "In rugby, players pass the ball by throwing it to team mates, don't they? 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE: Can use 'that's all' to end a letter.  (PRONOUNS: demonstratives)\n",
      "That's all for now. \n",
      "\n",
      "Well I think that's all.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6039760363101959\n",
      "Accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3996618437767029\n",
      "Accuracy: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.178541961312294\n",
      "Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████████████████████████████████████▌                                             | 826/1250 [01:10<00:36, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You can work really hard for a couple of days, then that's all. 1\n",
      "But that's all. 2\n",
      "You're just a chicken that's all. 2\n",
      "Yes, that's all. 2\n",
      "Good, that's all then. 2\n",
      "Good, that's all then. 2\n",
      "I used to play the piano a bit that's all. 2\n",
      "That's all for today. 2\n",
      "That will be all. 2\n",
      "Here is the agenda for the meeting and that's all for the messages. 2\n",
      "That is all, it would take me years haha, It is smart to use protection while learning. 2\n",
      "But that's not all. 1\n",
      "That's all right then. 2\n",
      "And is that all? 1\n",
      "That will be all for now. 2\n",
      "Yeah, is that all? 1\n",
      "Oh, is that all? 1\n",
      "Oh, is that all? 1\n",
      "No, that's all right. 1\n",
      "I 'm the one person who can make this country great again, that's all I know, he told reporters Saturday. 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE: Can use 'these' as a pronoun to refer to something with immediate relevance which has already been mentioned.  ►  noun phrases  ►  pronouns: demonstrative (PRONOUNS: demonstratives)\n",
      "He is very clever and generous, and these are the things that I like most about him. \n",
      "\n",
      "There are a few interesting and funny programmes like The Simpsons, Password or José Mota's hour. These are the only programmes I like watching. \n",
      "\n",
      "I think that we have similar taste about things like these.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 18.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5731527447700501\n",
      "Accuracy: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3150770592689514\n",
      "Accuracy: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.18169493973255157\n",
      "Accuracy: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████▋                                            | 837/1250 [01:12<00:35, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "I worked on the new line for many months, and these are the elements I hope I managed to incorporate into them. 2\n",
      "These are the kinds of practical actions that inspire me in my job as we work to make the best science available to understand and reduce the impact of extreme events on families, communities and businesses. 2\n",
      "These are just some of the ways his company changed everything – for better or worse. 2\n",
      "Those are the ones I get the most personally invested in. 1\n",
      "These are the important things for our society when these people are released.” I spoke to a former prisoner who now runs a social enterprise called X-Cons Sweden. 2\n",
      "And this man is involved in getting investment from UK to Africa, and he was very excited about Telepathy, that it would be a way of educating people about Africa, of showing them other people’s point of view.” \n",
      "This is Iguchi’s fondest hope – that seeing somebody else’s literal point of view will help you to see their metaphorical point of view. 1\n",
      "These are the sort of questions\n",
      "that should have been raised at the\n",
      "briefing session. 2\n",
      "These are just some of the things Stephanie experienced during her visit to Los Angeles. 2\n",
      "These were the basic ingredients for complex language. 2\n",
      "Those were her words, not mine. 1\n",
      "I would say almost all the eggs I eat are laid by chickens, as these are the most common eggs for people to eat. 2\n",
      "Yoga was mainly popularized in the 1980's in the west, as this is when it primarily became exercise. 1\n",
      "I told him 'yes', he smiled, and told me in all seriousness, that yes, he absolutely believed that humans would reach Mars in my lifetime.” \n",
      "She told the project: “When I first heard about the Mars One project I thought, this is my chance – that childhood dream could become a reality. 1\n",
      "I see, those are the two big shot cities so that makes sense. 1\n",
      "These are the sensorial fitness smart socks. 2\n",
      "Well, those are my terms. 1\n",
      "Those are some ex-tra ex-amples for you. 1\n",
      "Mmm, well this is our “ I'm sorry I cheated on you ” package. 1\n",
      "I mean, there are fish steaks, ground meat steaks, pork steaks, and those are just to name a few. 1\n",
      "Carson began his entertainment career at the age of 14 when he appeared at county fairs as a magician, which was his first love. 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORM: Can form a cleft construction beginning with 'it' to emphasise the subject of the main clause. ► clauses (PRONOUNS: subject/ object)\n",
      "It was my father who took all this away from me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.37615697741508486\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.08096974745392799\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.029563990235328675\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████▌                                                                                              | 369/1250 [00:30<01:13, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It is these factors that led the Oregon Resilience Plan to conclude that in a worst-case scenario, 10,000 people could be killed, and large areas of Oregon could be without transportation, electricity, water and sewer for several months to several years. 2\n",
      "It was in 1963 that their enormous fame first came about with the Beatlemania 2\n",
      "Crowe spent much of his life living in Australia and the United States, but it was in New Zealand where he first became involved in the entertainment industry. 2\n",
      "It was not until the 15th century that “breakfast” came into use in written English to describe a morning meal, which literally means to break the fasting period of the prior night 2\n",
      "When he finds Princess Leia's message to Obi-Wan Kenobi inside the robot R2D2, it is 'the call to adventure' that starts the hero on his journey. 2\n",
      "It was on the Tiananmen rostrum where Chairman Mao formally proclaimed the founding of the People's Republic. 2\n",
      "It was in the 10th century that the actual word \"pizza\"  was first recorded! 2\n",
      "It wasn't until Phil was about 12 years old that he began to realize that there were better things out there in the world. 2\n",
      "It’s the landscapers, the nannies, the waitresses – they are all relying on that summer income to get them through the winter but people don’t see that when they’re coming out on holiday. 2\n",
      "Although it wasn't until the recent codification of the game that they instituted the ban on handling the ball (with the exception of the goalkeeper). 2\n",
      "FIFA wasn't around since the year 195, if so it could have been Jesus' apostles who started the game by trying to get the ball in each others nets. 2\n",
      "It was his money and his car, and he was determined to do this alone. 1\n",
      "It is often they who are charged with doing the street dealing or even the stabbing, he says. 2\n",
      "But it wasn't just you who was involved, right? 2\n",
      "We think it was John D White for Docutel in the US.” \n",
      "Even better for Goodfellow, his achievement has been officially recognized in the latest edition of a 180-page guidebook called Life in the United Kingdom. 1\n",
      "You know, it's the boating that I don't like. 2\n",
      "Remember it is the boss who hires you and tell her how much you have improved the office efficiency. 2\n",
      "Mid-Atlantic/Northeast: Weirdly warm\n",
      "If there is one present being handed out on as winter begins, it is the well above-average temperatures in the Mid-Atlantic. 2\n",
      "It was her coworker. 1\n",
      "Each year Larry Harvey\n",
      "announces a theme for the event to provide them with inspiration – in the year 2006,\n",
      "for example, it was ‘Hope and Fear’. 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORM/USE: Can use 'be' + 'not' + adjective + 'that-' clause to make an assertion less direct. (MODALITY: expressions with be)\n",
      "[talking about a town near a dump where people cannot open their windows] I am not certain that they have got used to it. \n",
      "\n",
      "[talking about distractions while studying] It's not likely that you'll make progress. \n",
      "\n",
      "As you can see, I'm really in favour of this plan but I'm not sure that the council has anticipated everything.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3671160113811493\n",
      "Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.10389510571956634\n",
      "Accuracy: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.04626576133072376\n",
      "Accuracy: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████████▏                                                                                                                       | 132/1250 [00:11<01:33, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "It's not clear how weapons, fighter jets and ammunition flowing into Syria will affect the fighting there, much less the heretofore unsuccessful attempts to forge a negotiated settlement. 1\n",
      "I'm not sure, They say humans need different social experiences to learn their own culture and to survive which most do learn in homeschooling. 1\n",
      "Yes, the cats we have are domesticated, small, and typically furry, but I'm really not sure when they were. 1\n",
      "Well it's not surprising that it's the world's largest restaurant chain by revenue, so you are not the only one eating a lot of fast food 1\n",
      "As for \"The Canadian\", I'm not sure of it's first operating year. 1\n",
      "I'm not sure if we've got any now.Books of that kind are on this shelf.Well, I'm afraid we've sold out. 1\n",
      "Much as I love them personally, I do n't sell things like saris -- and I never would -- it's not a style that would appeal to the tastes of my particular customers. 1\n",
      "Well, I'll celebrate Hanukah soon, but that's not as important to us as Christmas is to you. 1\n",
      "I'm not sure about sports, but they contribute a great deal to the arts and Madrid is one of the world's major global cities. 1\n",
      "Studying in the university is not easy, but it's not as arduous as you think. 1\n",
      "I am not sure what a handicapped spot is. 1\n",
      "It's not a completely resilient piece of nature we can do anything with. 1\n",
      "I am not sure about common types of wedding cakes. 1\n",
      "I am not overly familiar with most of it. 1\n",
      "But I'm not so sure. 1\n",
      "A few nights, I'm not quite sure of my schedule yet. 1\n",
      "It's not the easiest thing in the world to switch to. 1\n",
      "But that's not all. 1\n",
      "I'm not so easily coaxed into doing something that I think is wrong. 1\n",
      "I'm not sure yet! 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE: Can use the present simple with a wide range of reporting verbs, especially in academic contexts, including 'demonstrate', 'illustrate'. (PRESENT: present simple)\n",
      "The popularity of this TV game in Russia clearly demonstrates the nature of human fears and dreams. \n",
      "\n",
      "The 2 charts illustrate the number of employees, and the trends in profit for three factories, namely the factories located in London, Leeds, and Bristol, which belong to the same company, during the year 2003.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5689870703220368\n",
      "Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████████▌                                                                                                                         | 3/25 [00:00<00:01, 17.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCan-do statement\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuperCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(rule[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExample\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mget_trained_classifer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43megp_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m scores, tokens \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mscore_corpus(classifier, dataloader, max_positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m, max_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1250\u001b[39m)\n\u001b[1;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m [(score, token, sample) \u001b[38;5;28;01mfor\u001b[39;00m score, token, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(scores, tokens, sentences[:\u001b[38;5;28mlen\u001b[39m(scores)]) \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m]\n",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m, in \u001b[0;36mget_trained_classifer\u001b[0;34m(rule, egp_examples)\u001b[0m\n\u001b[1;32m      7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_dataset(positive, negative, others, models\u001b[38;5;241m.\u001b[39mbert_tokenizer, \u001b[38;5;241m64\u001b[39m) \n\u001b[1;32m      8\u001b[0m train_dataloader, val_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_loaders(dataset)\n\u001b[0;32m---> 10\u001b[0m optimizer, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classifier\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/grammarctg/experiments/../source/models.py:124\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, num_epochs, lr, criterion, optimizer)\u001b[0m\n\u001b[1;32m    121\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    122\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[1;32m    125\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    126\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/tqdm/std.py:1180\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1180\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/grammarctg/experiments/../source/data.py:113\u001b[0m, in \u001b[0;36mSentenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 113\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: encoding[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten(),\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    118\u001b[0m     }\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2803\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2802\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2803\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2909\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2890\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2891\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2906\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2907\u001b[0m     )\n\u001b[1;32m   2908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2909\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2928\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2982\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2974\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2975\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2979\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2980\u001b[0m )\n\u001b[0;32m-> 2982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3000\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3001\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/transformers/tokenization_utils.py:722\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    720\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_for_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfirst_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpair_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecond_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3461\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.prepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   3459\u001b[0m \u001b[38;5;66;03m# Padding\u001b[39;00m\n\u001b[1;32m   3460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mor\u001b[39;00m return_attention_mask:\n\u001b[0;32m-> 3461\u001b[0m     encoded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_length:\n\u001b[1;32m   3470\u001b[0m     encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3226\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3222\u001b[0m     )\n\u001b[1;32m   3224\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m-> 3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrequired_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSized\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   3227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_attention_mask:\n\u001b[1;32m   3228\u001b[0m         encoded_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/mnt/qb/work/meurers/mpb672/conda_envs/gctg/lib/python3.10/abc.py:117\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Register a virtual subclass of an ABC.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Returns the subclass, to allow usage as a class decorator.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _abc_register(\u001b[38;5;28mcls\u001b[39m, subclass)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _abc_instancecheck(\u001b[38;5;28mcls\u001b[39m, instance)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while not criterion(coded_instances, num_rules=19):\n",
    "    rule = egp_examples.sample(1).iloc[0] # sample random rule\n",
    "    if rule['#'] in coded_instances['#']: continue\n",
    "    print(f\"{rule['type']}: {rule['Can-do statement']} ({rule['SuperCategory']}: {rule['SubCategory']})\")\n",
    "    print(rule['Example'])\n",
    "\n",
    "    classifier = get_trained_classifer(rule['augmented_examples'], rule['augmented_negative_examples'], get_others(egp_examples, rule['#']))\n",
    "    scores, tokens = models.score_corpus(classifier, dataloader, max_positive=250, max_batches=1250)\n",
    "    results = [(score, token, sample) for score, token, sample in zip(scores, tokens, sentences[:len(scores)]) if score > 0.5]\n",
    "    sorted_results = iter(sorted(results, key=lambda x: x[0], reverse=True))\n",
    "    while len(coded_instances[coded_instances['#'] == rule['#']]) < 20:\n",
    "        if len(coded_instances[coded_instances['#'] == rule['#']]) >= 10: # check if we have at least 40% after 10 instances\n",
    "            if not criterion(coded_instances[coded_instances['#'] == rule['#']], 0.4, 0): break\n",
    "        score, token, sample = next(sorted_results)\n",
    "        user_response = input(f\"{sample}\")\n",
    "        new_row = pd.DataFrame({'#': [rule['#']],\n",
    "             'sentence': [sample],\n",
    "             'correct': [True if user_response == '2' else False],\n",
    "             'score': [score],\n",
    "             'max_token': [token]})\n",
    "        coded_instances = pd.concat([coded_instances, new_row], ignore_index=True)\n",
    "        coded_instances.to_json(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea3258-ffef-4e2a-bd6a-4fbbd6057217",
   "metadata": {},
   "source": [
    "# Analyse coded instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a6945a48-16b0-4bdf-ac78-370e938edc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_model(model, probes):\n",
    "    encoded_input = models.bert_tokenizer(probes, return_tensors='pt', max_length=64, padding='max_length', truncation=True).to(models.device)\n",
    "    with no_grad():\n",
    "        values, indices = model(encoded_input['input_ids'], encoded_input['attention_mask'], diagnose=False)\n",
    "    tokens = [models.bert_tokenizer.convert_ids_to_tokens(ids) for ids in encoded_input['input_ids']]\n",
    "    max_tokens = [token[indices[i]] for i, token in enumerate(tokens)]\n",
    "    return values.cpu(), max_tokens\n",
    "    \n",
    "def save_classifier(classifier, nr):\n",
    "    trainable_params = {name: param for name, param in classifier.named_parameters() if param.requires_grad}\n",
    "    save(trainable_params, f'../models/frozen_bert/{nr}.pth')\n",
    "    \n",
    "def load_classifier(nr):\n",
    "    trainable_params = load(f'../models/frozen_bert/{rule[\"#\"]}.pth')\n",
    "    classifier = models.RuleDetector(models.bert_encoder)\n",
    "    with no_grad():\n",
    "        for name, param in classifier.named_parameters():\n",
    "            if name in trainable_params:\n",
    "                param.copy_(trainable_params[name])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99640040-f938-498f-a5ff-8b4797051e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#\n",
       "129     1.00\n",
       "285     0.85\n",
       "319     1.00\n",
       "678     1.00\n",
       "708     1.00\n",
       "732     1.00\n",
       "874     0.95\n",
       "888     1.00\n",
       "1100    0.85\n",
       "1217    1.00\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_per_rule = coded_instances.groupby('#')['correct'].mean()\n",
    "correct_per_rule[correct_per_rule > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0907680c-8dbd-4137-8b15-952877fcbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE: Can used affirmative 'could' have + '-ed' to talk about past possibility.  (MODALITY: could)\n",
      "Alice was disappointed that her mother could have phoned her but she did not. \n",
      "\n",
      "I think that all these problems could have been avoided and that asking my money back is the best way of forgetting that evening. \n",
      "\n",
      "I was grateful to them because the ticket was so expensive that I couldn't have bought it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5118956390023232\n",
      "Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1385013009607792\n",
      "Accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 19.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.08948708288371562\n",
      "Accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "rule = egp_examples.iloc[1216] \n",
    "print(f\"{rule['type']}: {rule['Can-do statement']} ({rule['SuperCategory']}: {rule['SubCategory']})\")\n",
    "print(rule['Example'])\n",
    "\n",
    "classifier = get_trained_classifer(rule['augmented_examples'], rule['augmented_negative_examples'], get_others(egp_examples, rule['#']), num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "155412a4-b7f7-464e-abb8-cb3c913afff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9432]), ['have'])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_model(classifier, [\"I should have gone crazy.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a3cf5feb-f953-4ec3-bccf-66e21c1d501c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████▊                                                                               | 250/1250 [00:20<01:22, 12.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8380135893821716,\n",
       "  'have',\n",
       "  \"Even I could n't have imagined that, Hoover said.\"),\n",
       " (0.8718549013137817,\n",
       "  'have',\n",
       "  'This is the best thing that could have happened to him, said Bonaduce, who in the past has struggled with addiction and legal troubles.'),\n",
       " (0.6777682900428772,\n",
       "  'have',\n",
       "  'Insects are plentiful – globally, for every human there are 40 tonnes of insects – so there is not too much chance of them being endangered, and they are unlikely to have been dosed with chemicals.'),\n",
       " (0.845260500907898,\n",
       "  'have',\n",
       "  \"The notes show that responses by Allen, the prosecution's star witness, were inconsistent with testimony he gave against Stevens, and that information from the interview could have benefited Stevens at trial, the motion says.\"),\n",
       " (0.7542694807052612,\n",
       "  'have',\n",
       "  'The fact that scientist have found evidence that planets such as Venus and Mars could have been hospititible enivronments leads me to think that alien life is a possibility'),\n",
       " (0.6991704702377319,\n",
       "  'have',\n",
       "  'There is no telling how many more victories and titles he could have won during his stolen prime.'),\n",
       " (0.6724197268486023, 'have', 'Could have been endangered snails.'),\n",
       " (0.5309225916862488,\n",
       "  'have',\n",
       "  \"After a weekend of intense investigation, authorities are piecing together more details about Friday's fatal shooting at Los Angeles International Airport, including the suspect's behavior earlier in the week and a warning from his family that may have come minutes too late.\"),\n",
       " (0.9522252082824707,\n",
       "  'have',\n",
       "  'Another possible escape route could have involved Inky squeezing into an open pipe at the top of his tank, which led under the floor to the drain.'),\n",
       " (0.5434989333152771,\n",
       "  'have',\n",
       "  \"The Mississippi Parole Board and Barbour are at a loss to explain how Bostick's pardon could have unfolded the way it did.\"),\n",
       " (0.8107188940048218,\n",
       "  'have',\n",
       "  'Rocky got excited, because he never would have thought he would see a no-hitter, especially the Dodgers pitch a no-hitter.'),\n",
       " (0.8621422648429871,\n",
       "  'have',\n",
       "  \"She struggles to understand how state officials could not have known that the man involved in her daughter's violent crash was the same Harry Bostick who had petitioned for a pardon.\"),\n",
       " (0.5165398716926575,\n",
       "  'have',\n",
       "  \"EPA officials say they feared that number would have become the norm and that's why, they say, the directive was issued.\"),\n",
       " (0.7385517358779907,\n",
       "  'have',\n",
       "  'I never would have thought that it originated from another country, I see heavy metal as a mostly american thing.'),\n",
       " (0.7710379362106323,\n",
       "  'have',\n",
       "  'They were all sitting in the living room watching TV.They had no idea a tornado was coming toward their house.If it had hit them, they could have all been killed.'),\n",
       " (0.5163019299507141,\n",
       "  'have',\n",
       "  'Huh, that is interesting, I could have almost 10 dogs of my breed for one of those, that is crazy'),\n",
       " (0.5775643587112427,\n",
       "  'have',\n",
       "  \"It would have been longer if there wasn't a hold on my record.\"),\n",
       " (0.6880598068237305,\n",
       "  'have',\n",
       "  'The best move UFC could have ever made was making Dana White president in 2001!'),\n",
       " (0.6015588045120239,\n",
       "  'have',\n",
       "  'I would have been so annoyed if I had to play sports with glasses on.'),\n",
       " (0.7341096997261047,\n",
       "  'have',\n",
       "  'I could have stayed in bed for another half hour.'),\n",
       " (0.5706565380096436,\n",
       "  'have',\n",
       "  'That was a long time ago, but I would have thought it would have been around longer than that.'),\n",
       " (0.5177714228630066,\n",
       "  'have',\n",
       "  'Even the surliest cynic cannot have failed to be thrilled by Robin van Persie’s extraordinary diving header for the Netherlands against Spain.'),\n",
       " (0.7321683764457703,\n",
       "  'have',\n",
       "  'That appears to have been the strategy for urban development in China over the last decade, during what has arguably been the largest and fastest urbanization of a society in modern history.')]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, tokens = models.score_corpus(classifier, dataloader, max_positive=250, max_batches=250, threshold=0.5)\n",
    "[(score, token, sample) for score, token, sample in zip(scores, tokens, sentences[:len(scores)]) if score > 0.5 and token==\"have\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3923ca4c-9231-4d08-be09-9a8c62394dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9572184681892395,\n",
       "  'have',\n",
       "  \"Even I could n't have imagined that, Hoover said.\"),\n",
       " (0.9714571237564087,\n",
       "  'have',\n",
       "  'This is the best thing that could have happened to him, said Bonaduce, who in the past has struggled with addiction and legal troubles.'),\n",
       " (0.9639521837234497,\n",
       "  'be',\n",
       "  \"I do n't think there would be any development that would be a negative impact on the environment.\"),\n",
       " (0.9616629481315613,\n",
       "  'have',\n",
       "  'maybe you should have placed them horizontally over your bowl or plate.'),\n",
       " (0.9590727090835571, 'be', \"There can't be much noise or traffic there.\"),\n",
       " (0.9601249694824219,\n",
       "  'have',\n",
       "  'But I think it would have been wiser, far wiser, for the administration to have notified, certainly the leadership of Congress in the interest of having good relations.'),\n",
       " (0.9519692063331604,\n",
       "  'be',\n",
       "  '“There’ll be a point here pretty soon where I’ll start feeling that kind of culture shock,” he said.'),\n",
       " (0.962639570236206,\n",
       "  'have',\n",
       "  'I would have thought they would run in kilometers.'),\n",
       " (0.9681951999664307,\n",
       "  'be',\n",
       "  \"Even on your darkest days, there will always be someone that's worse than you are, unfortunately, Wright told ITN.\"),\n",
       " (0.9791218638420105,\n",
       "  'have',\n",
       "  'Another possible escape route could have involved Inky squeezing into an open pipe at the top of his tank, which led under the floor to the drain.'),\n",
       " (0.9827558994293213,\n",
       "  'be',\n",
       "  'During ancient times in Rome and Greece there would be all kinds of roadside stalls and markets selling this kind of food.'),\n",
       " (0.9771115183830261,\n",
       "  'have',\n",
       "  'Rocky got excited, because he never would have thought he would see a no-hitter, especially the Dodgers pitch a no-hitter.'),\n",
       " (0.9593765139579773,\n",
       "  'have',\n",
       "  \"She struggles to understand how state officials could not have known that the man involved in her daughter's violent crash was the same Harry Bostick who had petitioned for a pardon.\"),\n",
       " (0.9628256559371948,\n",
       "  'be',\n",
       "  'There needs to be cultural change in our prescribing behaviours and more restraint in the use of antibiotics in farming and agriculture.'),\n",
       " (0.9608239531517029,\n",
       "  'be',\n",
       "  'I understand that mistakes happen but there needs to be a minimum of two pharmacists at all times so all prescriptions can be checked.'),\n",
       " (0.9558117389678955,\n",
       "  'have',\n",
       "  'We only wished that my father would have been a part of it.'),\n",
       " (0.9573189616203308, 'have', \"It wasn't as high as I would have liked.\"),\n",
       " (0.9656003713607788,\n",
       "  'been',\n",
       "  'There had always been a bit of bad blood between the two teams over the years.'),\n",
       " (0.9744969606399536,\n",
       "  'have',\n",
       "  'I never would have thought that it originated from another country, I see heavy metal as a mostly american thing.'),\n",
       " (0.9581079483032227,\n",
       "  'have',\n",
       "  'That is pretty interesting, I would have never guessed.'),\n",
       " (0.9541643261909485, 'have', \"What good would it have done if I'd gone out?\"),\n",
       " (0.9695558547973633,\n",
       "  'be',\n",
       "  \"Huh, so do you think there'll be better train systems between cities?\"),\n",
       " (0.9518108367919922,\n",
       "  'have',\n",
       "  'They were all sitting in the living room watching TV.They had no idea a tornado was coming toward their house.If it had hit them, they could have all been killed.'),\n",
       " (0.9669277667999268,\n",
       "  'have',\n",
       "  \"It would have been longer if there wasn't a hold on my record.\"),\n",
       " (0.973702073097229,\n",
       "  'have',\n",
       "  'I would have been so annoyed if I had to play sports with glasses on.'),\n",
       " (0.9680057168006897,\n",
       "  'have',\n",
       "  'I could have stayed in bed for another half hour.'),\n",
       " (0.9628225564956665,\n",
       "  'be',\n",
       "  'Asked whether or not she expected there to be enough customers to fill the giant office park, Song said, Altogether, probably not.'),\n",
       " (0.9659630656242371,\n",
       "  'have',\n",
       "  'That was a long time ago, but I would have thought it would have been around longer than that.')]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e748c401-0833-4fee-aae2-1cdb4b3aa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier(classifier, rule[\"#\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba318c81-d16f-480b-88d8-53f3c0257b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_special_examples(instruction):\n",
    "    prompt = f'{helpers.get_prompt(rule, n_examples=0, mark_words=False)}Create 25 examples that {instruction}.'\n",
    "    messages = [ { \"role\": \"user\", \"content\": prompt }]\n",
    "    response = api.get_openai_chat_completion(messages, max_tokens=512)[0]\n",
    "    examples, _  = helpers.parse_response(response)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3f3a0a24-51d6-49ca-a33f-abe794b85fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If you had told me earlier, I would have picked you up from the airport.', 'She would have passed the exam if she had studied harder.', 'They would have gone on vacation with us if they had the time.', 'I would have gone to the concert if I had known about it.', 'We would have helped you move if you had asked us.', 'He would have bought the car if it had the features he was looking for.', 'The team would have won the game if they had scored in the final minute.', 'If he had invited me, I would have gone to his birthday party.', \"She would have finished her project sooner if she hadn't gotten sick.\", 'They would have booked the hotel room if they had found a good deal.', 'If she had seen the movie, she would have understood the reference.', \"I would have gone to the beach with you if it hadn't been raining.\", \"We would have celebrated our anniversary if we hadn't been busy.\", 'He would have gotten the job if he had followed up after the interview.', 'They would have bought the house if it had a bigger backyard.', 'If I had known you needed help, I would have offered.', \"She would have attended the meeting if she hadn't been out of town.\", 'He would have fixed the leak if he had the right tools.', 'If they had arrived on time, they would have caught the train.', 'I would have cooked dinner if I had known you were coming over.', \"We would have stayed longer if the hotel hadn't been fully booked.\", 'They would have taken the class if they had met the requirements.', 'If she had remembered the appointment, she would have shown up.', 'I would have invited you to the party if I had known your phone number.', \"We would have visited the museum if it hadn't been closed for renovations.\"]\n"
     ]
    }
   ],
   "source": [
    "extra_examples = get_special_examples('use would have instead.')\n",
    "print(extra_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b57a42b6-a4ed-4f23-802b-2dd0310b26c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3282320400079091\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 21.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.20652184883753458\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 23.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.19095894694328308\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = get_trained_classifer(random.sample(rule['augmented_examples'], 2 * len(extra_examples)),\n",
    "                                   random.sample(rule['augmented_negative_examples'], len(extra_examples)) + extra_examples,\n",
    "                                   [], classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4ce86dbd-edf7-425c-a870-732c7aa023ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0590]), ['have'])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe_model(classifier, ['I should have been fallen for her.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eba56fc7-419f-40a9-a5f8-6ea606a7e833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72ef9f05-7751-4394-b1fc-31d0830caab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1febb567-b31b-49c1-8599-fd98105e9fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
