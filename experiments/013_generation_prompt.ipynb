{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8aed03-cb38-492a-8fab-60d1e35b727c",
   "metadata": {},
   "source": [
    "# Exp013: Create prompts for grammar-controlled text generation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86dccf97-0992-4cf4-abd1-4fb96ef2e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/dglandorf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/dglandorf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'data' from '/cluster/home/dglandorf/grammarctg/experiments/../source/data.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../source')\n",
    "import models\n",
    "import data\n",
    "import api\n",
    "import importlib\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f04b5921-b170-4436-8d8d-cf189826d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "levels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"] \n",
    "level_idx = {level: i for i, level in enumerate(levels)}\n",
    "\n",
    "def skills(rules, statement=True):\n",
    "     if statement: return \"- \" + rules['SubCategory'] + \" - \" + rules['guideword'] + \": \" + rules['Can-do statement']\n",
    "     return rules['SubCategory'] + \" \" + rules['guideword']\n",
    "    \n",
    "def get_prompt(rules, snippet, negative_rules=None, dialog=True, all=False, level=None, statement=True):\n",
    "    sep = os.linesep if statement else \"; \"\n",
    "    if level:\n",
    "        constraints = f\"grammar skills on CEFR level {level}.\"\n",
    "    else: \n",
    "        exclude = f\"\"\"Do NOT apply the following grammar skills:\n",
    "    {sep.join(skills(negative_rules, statement=statement))}\n",
    "\"\"\" if negative_rules else \"\"\n",
    "        constraints = f\"\"\"{\"all\" if all else \"at least one\"} of these grammar skills:\n",
    "{sep.join(skills(rules, statement=statement))}\n",
    "{exclude}\"\"\"\n",
    "    return f\"\"\"Continue the {\"dialog with one turn\" if dialog else \"text with two sentences\"}, proving knowledge of {constraints}\n",
    "Snippet:\n",
    "{snippet}\"\"\"\n",
    "    \n",
    "def classify_sents(classifiers, rules, sentences, verbose=True):\n",
    "    results = []\n",
    "    for idx, rule in rules.iterrows():\n",
    "        scores = models.probe_model(classifiers[rule['#']], sentences)\n",
    "        hits = [sentences[i] for i, score in enumerate(scores[0]) if score > 0.5]\n",
    "        if verbose & len(hits): print(f'\\n{rule[\"Level\"]}-{rule[\"Can-do statement\"]} ({rule[\"#\"]})\\n{os.linesep.join([\"- \"+h for h in hits])}')\n",
    "        results.append(len(hits)/len(sentences))\n",
    "    return results\n",
    "\n",
    "def sample_adjacent(lst, n=3):\n",
    "    if len(lst) < n: raise ValueError(\"List must contain at least two items\")\n",
    "    index = random.randint(0, len(lst) - n)\n",
    "    return lst[index:index+n]\n",
    "    \n",
    "def sample_dialog_snippet(dialogs):\n",
    "    dialog = random.sample(dialogs, 1)[0]\n",
    "    utterances = sample_adjacent(dialog)\n",
    "    return os.linesep.join([(\"A\" if (i%2==0) else \"B\") + \": \" + utt for i, utt in enumerate(utterances + [\"\"])])\n",
    "\n",
    "def prompt_score(rules, snippet, classifiers, dialog, all, level=None, statement=True, verbose=False):\n",
    "    prompt = get_prompt(rules, snippet, dialog=dialog, all=all, level=level, statement=statement)\n",
    "    if verbose: print(prompt)\n",
    "    response = api.get_openai_chat_completion([{ \"role\": \"user\", \"content\": prompt}])[0] #, model=\"gpt-4-0125-preview\"\n",
    "    if verbose: print(\"RESPONSE from GPT3.5\")\n",
    "    if verbose: print(response)\n",
    "    return classify_sents(classifiers, rules, data.sent_tokenize(response), verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720d72c-001b-4258-acad-9f95a46c2241",
   "metadata": {},
   "source": [
    "Load EGP rules, topical prompts and dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecdf038-3b78-4ad5-87cc-7a84365738f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "egp = data.get_egp()\n",
    "cefr = data.CEFRTexts()\n",
    "stories = list(cefr.get_beginnings(100))\n",
    "ds = data.DialogSum()\n",
    "dialogs = ds.get_dialogues()\n",
    "classifiers = {nr: models.load_classifier(nr, 'corpus_training') for nr in [int(name.replace(\".pth\",\"\")) for name in os.listdir(f\"../models/corpus_training\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95833ffb-6fcf-41c5-aaf0-10042fc81a4c",
   "metadata": {},
   "source": [
    "## Task 1: Single constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fed6ed12-babd-4267-a841-da3363c58c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories = [\"would\", \"negation\", \"superlatives\"]\n",
    "level = \"A1\"\n",
    "n_per_subcat=1\n",
    "rules = egp[(egp['SubCategory'].isin(subcategories)) & (egp['Level']==level) & egp['#'].isin(classifiers.keys())].groupby(\"SubCategory\").sample(n_per_subcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231eb05-cefc-4ebd-96e1-b8bd76e7e0e2",
   "metadata": {},
   "source": [
    "For Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c50759e8-9cbc-404e-b730-6748bbb46ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue the text with two sentences, proving knowledge of all of these grammar skills:\n",
      "- negation - FORM: MODAL VERB 'CAN': Can use negative form 'can't'.\n",
      "- would - USE: WISHES AND PREFERENCES WITH 'LIKE': Can use 'would like' to talk about wishes and preferences.\n",
      "\n",
      "Snippet:\n",
      "\n",
      "The first chart illustrates the percentage of the population who owned a smartphone from 2011 to 2016, and the second breaks the percentages down by age for 2011 and 2016.\n",
      "RESPONSE from GPT3.5\n",
      "However, it is important to note that the data for 2016 is not entirely accurate, as some respondents refused to answer the survey. Therefore, we can't fully rely on the statistics presented in the second chart.\n",
      "\n",
      "A1-Can use negative form 'can't'. (1177)\n",
      "- Therefore, we can't fully rely on the statistics presented in the second chart.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5, 0.0]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet = random.sample(stories, 1)[0]\n",
    "prompt_score(rules, snippet, classifiers, dialog=False, all=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3571a8ef-bbd2-467a-aefd-a66c11d9ac80",
   "metadata": {},
   "source": [
    "For Dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af418ca8-1e3b-44f8-a77c-d2ccbc37ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue the dialog with one turn, proving knowledge of all of these grammar skills:\n",
      "- negation - FORM: MODAL VERB 'CAN': Can use negative form 'can't'.\n",
      "- would - USE: WISHES AND PREFERENCES WITH 'LIKE': Can use 'would like' to talk about wishes and preferences.\n",
      "\n",
      "Snippet:\n",
      "A: Can I take the subway to get there?\n",
      "B: Yes, but that will probably take about half an hour. You should just take a taix.\n",
      "A: Won't that be expensive?\n",
      "B: \n",
      "RESPONSE from GPT3.5\n",
      "Not necessarily, you can always share a ride with a friend or take a cheaper taxi service. Would you like me to look up some options for you?\n",
      "\n",
      "A1-Can use 'would like' to talk about wishes and preferences. (618)\n",
      "- Would you like me to look up some options for you?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.5]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet = sample_dialog_snippet(dialogs)\n",
    "prompt_score(rules, snippet, classifiers, dialog=True, all=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876556ad-af19-4d72-bcb9-50d58e944660",
   "metadata": {},
   "source": [
    "## Task 2: Combine subcategories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b77d9e-1ae4-4877-98c0-46fd26491794",
   "metadata": {},
   "source": [
    "Choose subcategory and level skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc8b7c4c-34ec-4548-8449-710f138a2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories = [\"would\", \"negation\", \"superlatives\"]\n",
    "levels = [\"B1\", \"B2\", \"B1\"]\n",
    "rules = pd.concat([egp[(egp['SubCategory'] == subcat) & (egp['Level']==level) & (egp['#'].isin(classifiers.keys()))] for subcat, level in zip(subcategories, levels)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6268d6-c11e-4d6c-8a5c-37274318e001",
   "metadata": {},
   "source": [
    "Assemble prompt for a random story beginning, test it with GPT3.5 and use classifiers to score the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275645fe-8cd0-48f7-a877-6089ac4b4c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue the text with two sentences, proving knowledge of at least one of these grammar skills:\n",
      "would FORM/USE: AFTER 'IF' CLAUSES; would FORM: PAST AFFIRMATIVE; would FORM: PAST NEGATIVE; would FORM: QUESTIONS; would FORM: WITH ADVERBS; would USE: FUTURE IN THE PAST; would USE: IMAGINED SITUATIONS IN THE PAST; would USE: INDIRECTNESS; would USE: POLITE REQUESTS; would USE: REPORTED SPEECH; would USE: WILLINGNESS IN THE PAST; negation FORM/USE: 'NOT', EMPHASIS; negation FORM/USE: 'NEVER', INVERTED FRONT POSITION, FOCUS; negation FORM/USE: 'NEITHER ... NOR'\n",
      "\n",
      "Snippet:\n",
      "Nobody knows which came first: the economic crisis tearing Greece apart or shisha, the drug now known as the “cocaine of the poor”.\n",
      "RESPONSE from GPT3.5\n",
      "If the economic crisis had not brought such devastation to Greece, perhaps the popularity of shisha would not have reached such heights. Would you happen to know where one can find reliable statistics on the correlation between the two phenomena?\n",
      "\n",
      "B1-Can use 'would' in the main clause of a conditional sentence to talk about an imagined situation, often in the context of advice or opinion-giving. (625)\n",
      "- If the economic crisis had not brought such devastation to Greece, perhaps the popularity of shisha would not have reached such heights.\n",
      "\n",
      "B1-Can use 'would have' + '-ed'. (626)\n",
      "- If the economic crisis had not brought such devastation to Greece, perhaps the popularity of shisha would not have reached such heights.\n",
      "\n",
      "B1-Can use 'would not have' + '-ed' or 'wouldn’t have' + '-ed' (627)\n",
      "- If the economic crisis had not brought such devastation to Greece, perhaps the popularity of shisha would not have reached such heights.\n",
      "\n",
      "B1-Can use question forms. (628)\n",
      "- Would you happen to know where one can find reliable statistics on the correlation between the two phenomena?\n",
      "\n",
      "B1-Can use 'would' to talk about imagined situations in the past. ► conditionals (631)\n",
      "- If the economic crisis had not brought such devastation to Greece, perhaps the popularity of shisha would not have reached such heights.\n",
      "\n",
      "B1-Can use 'would' with verbs such as 'advise', 'imagine', 'recommend', 'say' to be less direct. (632)\n",
      "- If the economic crisis had not brought such devastation to Greece, perhaps the popularity of shisha would not have reached such heights.\n",
      "\n",
      "B2-Can use uncontracted 'not' for emphasis or in formal contexts. (1192)\n",
      "- If the economic crisis had not brought such devastation to Greece, perhaps the popularity of shisha would not have reached such heights.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet = random.sample(stories, 1)[0]\n",
    "prompt_score(rules, snippet, classifiers, dialog=False, all=False, verbose=True, statement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcafb80-a1b7-497d-a5eb-ce2a8d46fea6",
   "metadata": {},
   "source": [
    "Do this with dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9211922e-4a41-484f-af63-2935d8ae034f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue the text with two sentences, proving knowledge of at least one of these grammar skills:\n",
      "would FORM/USE: AFTER 'IF' CLAUSES; would FORM: PAST AFFIRMATIVE; would FORM: PAST NEGATIVE; would FORM: QUESTIONS; would FORM: WITH ADVERBS; would USE: FUTURE IN THE PAST; would USE: IMAGINED SITUATIONS IN THE PAST; would USE: INDIRECTNESS; would USE: POLITE REQUESTS; would USE: REPORTED SPEECH; would USE: WILLINGNESS IN THE PAST; negation FORM/USE: 'NOT', EMPHASIS; negation FORM/USE: 'NEVER', INVERTED FRONT POSITION, FOCUS; negation FORM/USE: 'NEITHER ... NOR'\n",
      "\n",
      "Snippet:\n",
      "A: Sir, I am very glad to tell that we have successfully registered the trademark for our new product. It is the time to think of some effective promoting strategies. We are beginning to get more attention from overseas.\n",
      "B: Well done, Fred. Do you know something useful for our promotion for our I-series?\n",
      "A: OK, Let me see. I suppose we must strengthen our promotion, because our brand is still new to some consumers. Maybe we should start our advertising program with our local and overseas distributors simultaneously, because they stand on a better position for selecting the best ways to advertise in market places. Besides, the advertisement fund can encourage them to spend more attention on advertising our products.\n",
      "B: \n",
      "RESPONSE from GPT3.5\n",
      "That sounds like a good plan. Would you be willing to lead this initiative and work closely with our distributors to ensure the success of our advertising campaign? And could you please report back to me with the progress and any feedback from the distributors?\n",
      "\n",
      "B1-Can use question forms. (628)\n",
      "- Would you be willing to lead this initiative and work closely with our distributors to ensure the success of our advertising campaign?\n",
      "\n",
      "B1-Can use 'would' to make polite requests, often in the fixed expression 'would you mind'. (633)\n",
      "- Would you be willing to lead this initiative and work closely with our distributors to ensure the success of our advertising campaign?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet = sample_dialog_snippet(dialogs)\n",
    "prompt_score(rules, snippet, classifiers, dialog=True, all=False, verbose=True, statement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597ecdf-abfe-4998-bd60-5513dbf9c5a4",
   "metadata": {},
   "source": [
    "## Task 3: All skills from one difficulty level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9ee1add-a19d-4fd9-a421-22fbc905cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"A2\"\n",
    "rules = egp[(egp['Level']==level) & (egp['#'].isin(classifiers.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "44f00b26-1705-40f6-ac77-9dda35c24a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue the text with two sentences, proving knowledge of grammar skills on CEFR level A2.\n",
      "Snippet:\n",
      "Martha is at the grocery store, getting ready for a house party.\n",
      "RESPONSE from GPT3.5\n",
      "She buys chips, soda, and other snacks for her guests. Then, she heads to the checkout to pay for her items.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet = random.sample(stories, 1)[0]\n",
    "prompt_score(rules, snippet, classifiers, dialog=False, all=False, verbose=True, level=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c007342-a2f8-4bb9-9464-be3525580c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue the dialog with one turn, proving knowledge of grammar skills on CEFR level A2.\n",
      "Snippet:\n",
      "A: Sure, company rules are not very strict at this point.\n",
      "B: Thank you for telling me that.\n",
      "A: But remind you, there are some forbidden activities.\n",
      "B: \n",
      "RESPONSE from GPT3.5\n",
      "I understand. I will make sure to follow the rules carefully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet = sample_dialog_snippet(dialogs)\n",
    "prompt_score(rules, snippet, classifiers, dialog=True, all=False, verbose=True, level=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b5728-8e84-459a-8047-1408bad60b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
