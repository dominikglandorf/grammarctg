{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15365f89-66d7-45e1-ad97-dc4610aeeeb5",
   "metadata": {},
   "source": [
    "# Exp018: Conditional instruction fine-tuning\n",
    "This experiment aims at instruction fine-tuning from existing skills in the dataset to train the model on single constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c19775e-4db4-4d58-9310-0e82d15f32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 18:03:09.673926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/dglandorf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/dglandorf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from '/cluster/home/dglandorf/grammarctg/experiments/../source/evaluation.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['CACHE_DIR'] = f\"/scratch/tmp.{os.getenv('SLURM_JOB_ID')}.dglandorf\" # speed up model loading\n",
    "os.environ['WANDB_DIR'] = os.getenv('CACHE_DIR')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "\n",
    "import pickle\n",
    "from torch.utils.data import RandomSampler, Subset\n",
    "import numpy as np\n",
    "import json\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(f'../source')\n",
    "import helpers\n",
    "import models\n",
    "import evaluation\n",
    "import importlib\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d860d9f7-cfd7-4c60-8ab7-ac59fa12d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "out_file = '../data/corpus_classification_all.pkl'\n",
    "preprossed_dataset_file = '../data/SFT_data.jsonl'\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "nrs = [59] #[58, 616]#\n",
    "classifiers = {nr: models.load_classifier(nr, \"corpus_training\") for nr in nrs}\n",
    "EOP = \"[/INST]\"\n",
    "egp = helpers.get_egp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1bf8eb-e0b0-4d72-92de-39d59362eafa",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f860be6b-ba7d-498f-9147-f65d5d8b1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_file, 'rb') as f:\n",
    "    all_hit_indices = pickle.load(f)\n",
    "    all_hit_sentences = pickle.load(f)\n",
    "    extracts = pickle.load(f)\n",
    "\n",
    "data = [{\"context\": extracts[idx][0], \"response\": extracts[idx][1], \"nr\": nr} for nr in nrs for idx in all_hit_indices[nr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58eebd3e-f3da-4d9d-89c4-92bccf50d23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5716d4dfe784762901923e30a1acc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def formatting_func(example):\n",
    "    rules = egp[egp['#'].isin(example['nr'] if type(example['nr']) == list else [example['nr']])]\n",
    "    constraints = os.linesep.join(\"- \" + rules['SubCategory'] + \": \" + rules['Can-do statement']) # \" - \" + rules['guideword']\n",
    "    context = os.linesep.join([(\"A\" if (i%2==0) else \"B\") + \": \" + utt for i, utt in enumerate(example[\"context\"])])\n",
    "\n",
    "    instruction = f\"\"\"Write the response of A and include these grammatical items in the response:\n",
    "{constraints}\"\"\"\n",
    "   # instruction = 'Write an answer of A that includes the affirmative form of \"would like\".'\n",
    "    \n",
    "    prompt = f\"\"\"[INST] \n",
    "{instruction}\n",
    "Dialog:\n",
    "{context} {EOP} \n",
    "A: \"\"\"\n",
    "    completion = f\"{example['response']}</s>\"\n",
    "    \n",
    "    return prompt, completion, prompt+completion\n",
    "    \n",
    "with open(preprossed_dataset_file, 'w') as f:\n",
    "    for item in tqdm(data):\n",
    "        # line['prompt'], line['completion'] = formatting_func(item) # for completion chat format\n",
    "        item['prompt'], item['completion'], item['text'] = formatting_func(item)\n",
    "        #print(item)\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2f6bc-a141-4832-8f94-af0732f0b8da",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb69f077-228e-4054-95a7-9bd8c359bd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65da67ecfa0947b6af9ef92a3911a744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files=preprossed_dataset_file, split='train', cache_dir=os.getenv('CACHE_DIR'))\n",
    "train_test_split = dataset.train_test_split(test_size=0.05)\n",
    "train_dataset, test_dataset = train_test_split['train'], train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f055c75-4e39-4153-bbd6-66e03673461e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [\"I don't think too many people would agree with you.  Since they know it's out there and about them.  All those sites are supposed to self-police and ban people who are abusers and if they don't they should be taken off-line.\",\n",
       "  'Again, sounds good in theory but everyone has different things that may hurt them or make them feel a certain way.  Everyone could be banned if you look at it that way',\n",
       "  \"No. I don't agree.  But changing focus here, did you know the UN appointed an official ambassador to extraterrestrials in 2010 in case we ever have contact?  I wonder who it is.\",\n",
       "  'No, I did not hear that do you have any guesses as to whom?'],\n",
       " 'response': 'None whatsoever.  I will have to find out though!  Today is the shortest day of the year, when earth was first formed a day was only 5.5 hours long.  I guess our orbit changed (?)',\n",
       " 'nr': 59,\n",
       " 'prompt': \"[INST] \\nWrite the response of A and include these grammatical items in the response:\\n- superlatives: Can use prepositional phrases with 'in' + singular name of a place after a superlative adjective.\\nDialog:\\nA: I don't think too many people would agree with you.  Since they know it's out there and about them.  All those sites are supposed to self-police and ban people who are abusers and if they don't they should be taken off-line.\\nB: Again, sounds good in theory but everyone has different things that may hurt them or make them feel a certain way.  Everyone could be banned if you look at it that way\\nA: No. I don't agree.  But changing focus here, did you know the UN appointed an official ambassador to extraterrestrials in 2010 in case we ever have contact?  I wonder who it is.\\nB: No, I did not hear that do you have any guesses as to whom? [/INST] \\nA: \",\n",
       " 'completion': 'None whatsoever.  I will have to find out though!  Today is the shortest day of the year, when earth was first formed a day was only 5.5 hours long.  I guess our orbit changed (?)</s>',\n",
       " 'text': \"[INST] \\nWrite the response of A and include these grammatical items in the response:\\n- superlatives: Can use prepositional phrases with 'in' + singular name of a place after a superlative adjective.\\nDialog:\\nA: I don't think too many people would agree with you.  Since they know it's out there and about them.  All those sites are supposed to self-police and ban people who are abusers and if they don't they should be taken off-line.\\nB: Again, sounds good in theory but everyone has different things that may hurt them or make them feel a certain way.  Everyone could be banned if you look at it that way\\nA: No. I don't agree.  But changing focus here, did you know the UN appointed an official ambassador to extraterrestrials in 2010 in case we ever have contact?  I wonder who it is.\\nB: No, I did not hear that do you have any guesses as to whom? [/INST] \\nA: None whatsoever.  I will have to find out though!  Today is the shortest day of the year, when earth was first formed a day was only 5.5 hours long.  I guess our orbit changed (?)</s>\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e897370-34b9-4776-9d6c-5eaa66f24db6",
   "metadata": {},
   "source": [
    "## Load and prepare base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b489244c-bcab-4da7-ad02-abbce1048030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db53215ccd894573a1fbace91b65aedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32001, 4096)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, cache_dir=os.getenv('CACHE_DIR'), device_map=\"auto\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=os.getenv('CACHE_DIR'), device_map=\"auto\")\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, cache_dir=os.getenv('CACHE_DIR'), padding_side=\"right\")\n",
    "#tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token = '[PAD]'\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302a546-0eff-452a-b195-dbe6ceede8a9",
   "metadata": {},
   "source": [
    "### Inference with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7b3417-d8b5-4a79-a6a9-f1a138736462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompts, max_new_tokens=128):\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    model_input = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        token_ids = model.generate(**model_input, max_new_tokens=max_new_tokens, pad_token_id=32000)\n",
    "    return tokenizer.batch_decode(token_ids[:,model_input['input_ids'].shape[1]:], skip_special_tokens=True, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a331450b-9ac4-4a40-9e2a-2758706a076e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"I'm in awe of the advancements in computer technology. It's mind-boggling to think about the implications for the art industry and museums. If a computer can create a Mona Lisa replica that fools even the experts, what does that mean for the future? And the pace of innovation is only accelerating. I've heard about the Russian-made computer that runs on water, it's incredible!\\n\\nB:  Indeed, it's a fascinating time we live in. Some people find it terrifying, but others, like the Transhumanists, embrace the idea of\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = random.choice(test_dataset)\n",
    "#example = train_dataset[10]\n",
    "#example['nr'] = [58, 616]\n",
    "#example['text'] = formatting_func(example)\n",
    "#print(example['text'])\n",
    "print(example['nr'])\n",
    "\n",
    "generate([example['prompt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49778e-65db-444d-8833-022fefad35a8",
   "metadata": {},
   "source": [
    "## Evaluate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e2fadd-a5bf-44e0-8f74-731e7dbaf9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(contexts, outputs, constraints, eval_quality=False):\n",
    "    scores = {nr: models.probe_model(classifier, outputs)[0]>0.5 for nr, classifier in classifiers.items()}\n",
    "    distinct = [evaluation.calculate_distinct_n(list(np.array(outputs)[np.isin(constraints, nr)])) for nr in nrs]\n",
    "    if eval_quality:\n",
    "        iter_metrics = tqdm(evaluation.gpt_metrics.keys(), desc=\"Metrics\", total=len(evaluation.gpt_metrics))\n",
    "        iter_responses = lambda: tqdm(zip(contexts, outputs), desc=\"Responses\", total=len(outputs))\n",
    "        quality = {metric: [evaluation.get_single_response_metric(metric, context, output) for context, output in iter_responses()] for metric in iter_metrics}\n",
    "    return scores, distinct, (quality if eval_quality else {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1f788de-4d48-497b-99fd-add052918ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds, verbose=False, n=25, datasets={\"train\": train_dataset, \"test\": test_dataset}, eval_quality=False):\n",
    "    results = {}\n",
    "    for name, ds in datasets.items():\n",
    "        subset = dataset[RandomSampler(ds, num_samples=n)]\n",
    "        if verbose: print(subset['prompt'][0])\n",
    "        outputs = generate(subset['prompt'])\n",
    "        scores, distinct, quality = calc_metrics(subset['context'], outputs, subset['nr'], eval_quality)\n",
    "        if verbose:\n",
    "            for truth, output in zip(subset['completion'], outputs):\n",
    "                print(f\"Truth: {truth}\")\n",
    "                print(f\"Gener: {output}\")\n",
    "            print(f\"Grammar detected: {scores}\")\n",
    "            print(f\"Distinctiveness per constraint {distinct}\")\n",
    "            print(f\"Quality: {quality}\")\n",
    "        print(list(zip(outputs,scores[nrs[0]]))[:10])\n",
    "        \n",
    "        results.update({f\"{name}_success_{nr}\": scores[nr].float().mean().item() for nr in classifiers.keys()})\n",
    "        results.update({f\"{name}_{metric}\": np.mean(quality[metric]) for metric in quality.keys()})\n",
    "        results.update({f\"{name}_distinct\": np.mean(distinct)})        \n",
    "    return results\n",
    "\n",
    "#compute_metrics([], verbose=False, n=25, datasets={\"test\": test_dataset}, eval_quality=True) # test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b8ed6-4a6a-4237-acc5-e0633d076a4b",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "125626b6-a4ab-41eb-8940-fa8fa0745d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    #modules_to_save=[\"embeddings\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8ee436-02f3-47b9-b605-830bff043f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"../models/mistral_FT\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=6,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    #save_steps=25,\n",
    "    logging_steps=5,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"gctg\",\n",
    "    #load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    per_device_eval_batch_size=8,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa48307e-a483-404f-bb12-170ef022ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fa270ea2b44853877f62ec86ba86cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7a1a223b224cbbb7a3077561f4d329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/dglandorf/gctg/lib64/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "collator = DataCollatorForCompletionOnlyLM(\"[/INST]\", tokenizer=tokenizer)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    data_collator=collator,\n",
    "    #preprocess_logits_for_metrics = preprocess_logits_for_metrics,\n",
    "    compute_metrics=compute_metrics\n",
    "    #neftune_noise_alpha=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255a8ea4-8027-4101-8a7e-fbfa620066d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='339' max='339' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [339/339 08:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Train Success 59</th>\n",
       "      <th>Train Distinct</th>\n",
       "      <th>Test Success 59</th>\n",
       "      <th>Test Distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.158700</td>\n",
       "      <td>1.586072</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.603730</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.510516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.092700</td>\n",
       "      <td>1.547679</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.400289</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.546191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.262500</td>\n",
       "      <td>1.518550</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.661157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.218200</td>\n",
       "      <td>1.498181</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.560538</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.506250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.358700</td>\n",
       "      <td>1.479770</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.578292</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.514825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.272900</td>\n",
       "      <td>1.473559</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.674121</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.620219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ya I wonder if they do, I wonder if they have the highest court in the land?', tensor(True)), ('I think so. He is the only losing coach in the history of the university.', tensor(True)), ('ya, I wonder if they still ban it in the highest court in the land?', tensor(True)), ('I would like to visit the oldest university in the US, Harvard University', tensor(False)), (\"Nope, hockey is the most popular sport in Canada. It's the national sport of Canada.\", tensor(True)), ('Yes, Daytona Beach is the most famous beach in the world for its hard packed sand, and is the only beach in the world with a speedway on it.', tensor(True)), ('they are the 6th most popular dog in the world', tensor(True)), ('I wonder if they have a brewery there?', tensor(False)), (\"I know it's the most popular sport in the world.\", tensor(True)), (\"I'm not sure.  I'm not sure that the highest paid employee in the state of Kansas is worth it.  He's the only losing coach in the history of the University of Kansas.\", tensor(True))]\n",
      "[('Yes.  It was invented by James Naismith.  He is the only losing coach in the history of the University of Kansas.', tensor(True)), ('That is impressive. ', tensor(False)), ('I know, I know.  It is the most popular sport in the world.', tensor(True)), ('I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see. I see', tensor(False)), ('They are the most popular seafood in the world and the most consumed fish in the world.', tensor(True)), ('Yeah that is pretty funny.  I wonder if it is the only one in the world. ', tensor(True)), (\"I think so. It's the most popular coffee in the world.\", tensor(True)), ('it is the 4th largest city in the country, and it is the capital city', tensor(True)), (\"I'm not the only one in the world who pays high rent.\", tensor(True)), ('I think they are the best team in the league.', tensor(True))]\n",
      "[('Yeah it is.  It is the 3rd busiest airport in the world.', tensor(True)), (\"300 dozens is a lot of books. That's 3,600 books.\", tensor(False)), ('ive heard that cancun is one of the most popular tourist destinations in the world', tensor(True)), (\"I'm afraid this is the largest dress in the shop. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest dress in the world. It's the largest\", tensor(True)), ('I think my favorite is the 5th symphony. It is one of the most famous pieces in the world.', tensor(True)), ('I wonder if they have a basketball court in the top of the highest court in the land!', tensor(True)), ('Honda is the second largest Japanese car maker in the world.  It was founded in 1948.', tensor(True)), ('The Fall was one of the longest-serving bands in the history of rock music. They were active for 42 years.', tensor(True)), ('The mall is having a big sale. The biggest in the history of the mall.', tensor(True)), ('I agree. I think the tallest dog in the world was a Great Dane.', tensor(True))]\n",
      "[('That is a great story.  I wonder if he regrets it.  He is one of the best players in the history of the game.  He is the only player in the history of the NBA to win 5 NBA championships.', tensor(True)), ('Yes, the two regions have different styles and techniques, but they are both delicious. It is the most popular and copied in the world.', tensor(True)), ('That is amazing.  I wonder if he is the only player in the league that has never fumbled.', tensor(True)), (\"Yes you are correct. He is the only losing coach in Kansas history haha that's funny. He is the only losing coach in Kansas history.\", tensor(True)), ('It is the largest wealth gap in the world.  The top 1% of the population owns 50% of the wealth.', tensor(True)), ('I think it does.  The top 3 wealthiest presidents in history were JFK, Washington and Jefferson.', tensor(True)), ('I did not know that. I wonder if he was the only deaf QB in the league.', tensor(True)), (\"5th highest? Wow, I guess he's not the highest paid player in the league.\", tensor(True)), (\"I agree! It's amazing to think that the largest telescope in the world is in Hawaii and is the most expensive telescope in the world!\", tensor(True)), ('Blue is the third most popular color in the world.', tensor(True))]\n",
      "[(\"Yes it's one of the most famous landmarks in the world.\", tensor(True)), (\"The NBA is the premier men's professional basketball league in the world.\", tensor(True)), (\"I like the meat but I don't like the ketchup. I think it's too sweet. I like the taste of the meat and the bun. I don't need anything else.\", tensor(False)), ('ive seen it a few times and it is one of my favorite movies in the series', tensor(False)), ('4.9 million people live in alabama, making it the 30th largest state by area and the 31st most populous of the 50 united states', tensor(True)), (\"I wonder if he's the richest man in the world!\", tensor(True)), ('1 billionth the size of the biggest star discovered in our galaxy.', tensor(True)), (\"10 years is a big gap. I'm the youngest in my family, and I'm only 13. My oldest brother is 23.\", tensor(True)), (\"I agree, he's the best. He's the most successful solo artist in the history of the Beatles.\", tensor(True)), ('It is the best Batman movie in the history of the franchise.', tensor(True))]\n",
      "[('New York City is the most densely populated major city in the United States.', tensor(False)), ('10% of the world population owns 80% of the wealth.  That is not fair.', tensor(False)), ('I did not know that.  I wonder if he was the richest president in history.  The wealthiest president in American history was JFK.', tensor(True)), ('24 megapixels is the best in the market right now, so you should be good with that', tensor(True)), (\"I know how you feel. I'm the same. I'm always behind schedule.\", tensor(False)), ('He was the only losing coach in the history of the University of Kansas.', tensor(True)), (\"Yeah! It's one of the most popular games in the world.\", tensor(True)), ('I see. I wonder if they are the most expensive horses in the world.', tensor(True)), ('I think it is the only one in the world.  They have a great selection of books, and the money goes to help the blind.', tensor(True)), ('Yeah, it is called the highest court in the land.', tensor(True))]\n",
      "[(\"Yeah, it's a bit weird. But it's a good movie. It's one of the best movies in the world.\", tensor(True)), (\"Japan is the largest developed country in the world.  It's the third largest economy in the world.  It's a very advanced country.  It's also the most densely populated country in the world.  It's a very crowded place.  It's also the second most populous country in the world.  It's a very crowded place.  It's also the second most populous country in the world.  It's a very crowded place.  It's also the second most populous country in the world.  It's a very crowded place.\", tensor(True)), ('Yes, they do. It is the official winter sport of Canada.', tensor(True)), ('I did not. I heard that the US supreme court building has a basketball court on the top floor called the highest court in the land.', tensor(True)), ('I know! I wonder if they are related?  I also wonder if they are the most popular beer in the world?', tensor(True)), (\"Broadway is the highest grossing theatre district in the world! You'll have a great time!\", tensor(True)), (\"I think it was Jon Arbuckle. I wonder if he was the only one in the world who didn't know Garfield was the most popular cat in the world!\", tensor(True)), ('I wonder if it is the most popular genre in the world?', tensor(True)), (\"I'm going alone, I'm the only one in my family that likes to travel, I'm going to be the only one in the world that has been to the top 3 wealthiest countries in the world, I'm excited!\", tensor(True)), ('He was the first left handed quarterback in the league. ', tensor(True))]\n",
      "[('I know.  I wonder if he ever thought about that.  I know that the US Supreme Court building has a basketball court on the top floor called the highest court in the land.  I wonder if they ever play games there.', tensor(True)), (\"I know, he was the only losing coach in the University of Kansas's history.\", tensor(True)), (\"I think it's the most popular coffee in the world. It's really popular in China, too.\", tensor(True)), ('100%!  I wonder if the library of Alexandria was the largest in the world at the time.', tensor(True)), (\"I know how you feel. I'm the same way. I'm always behind schedule. I'm always trying to catch up. I'm always trying to do too much. I'm always trying to do too many things at once. I'm always trying to do too many things in too little time. I'm always trying to do too many things in too little space. I'm always trying to do too many things in too little money. I'm always trying to do too many things in too little time. I'm always trying to do too many things in too little space. I\", tensor(False)), ('Yeah, it is called the highest court in the land.  I wonder if they have a basketball team.', tensor(True)), (\"100%! I wonder if the inventor of basketball ever regretted inventing it, he was the only losing coach in the history of the university, that's gotta be a tough pill to swallow\", tensor(True)), (\"I think it's the only diet in the world that is actually a philosophy.\", tensor(True)), (\"I've heard that the food is the best in the world! I'd love to try it. \", tensor(True)), (\"I didn't know that. I'm not a fan of soccer, but it's the most popular sport in the world.\", tensor(True))]\n",
      "[(\"I'm not sure Trump will ever get reelected.  He's the least popular president in American history.  I'm not sure how he's still in office.  I think he's the most corrupt president in American history.  I'm not sure how he's still in office.  I think he's the most corrupt president in American history.  I'm not sure how he's still in office.  I think he's the most corrupt president in American history.  I'm not sure how he's still in office.  I think he'\", tensor(True)), ('Algeria is the tenth largest country in the world and the largest in Africa.', tensor(True)), (\"I think you should try it. It's the best Haunted House in the world.\", tensor(True)), ('I think it is,  I think the sun is the biggest star in our galaxy.', tensor(True)), ('I am the luckiest guy in the world. ', tensor(True)), ('270 million guns in the US. That is a lot of guns.', tensor(False)), (\"I don't know how they are captured but I know they are one of the most popular seafood in the world.\", tensor(True)), ('I wonder if he has a favorite room in the house. The top three wealthiest presidents in American history were JFK, Washington, and Jefferson.', tensor(True)), ('I like Dunkin Donuts too. I read that they are the largest coffee and baked goods chain in the world. ', tensor(True)), ('I know, I know.  I guess they were busy with the 1000 most powerful people in the world.', tensor(True))]\n",
      "[('100%. The US Supreme Court has a basketball court on the top floor known as the highest court in the land', tensor(True)), ('I think the judge was just trying to be cool and fun. I mean the supreme court building has a basketball court on the top floor called the highest court in the land', tensor(True)), (\"343 Industries is still making Halo games, and they are the best in the business. I'm not sure if they are still making Halo 3, but it's still the best in the series.\", tensor(True)), ('I think he would have been very uncomfortable. He is the least popular president in American history.', tensor(True)), ('100%! I wonder if the inventor of basketball is the only losing coach in history of the university, I would think he would be the best coach in the history of the university', tensor(True)), (\"I think so. It's the most popular coffee in the world.\", tensor(True)), ('I know. I wonder if they have a court in the White House. I know the Supreme Court has a basketball court on the top floor known as the highest court in the land.', tensor(True)), (\"I know! I think that's why they are the most popular sport in the world. It's amazing to think that the US Supreme Court has a basketball court on the top floor of the building, and they call it the highest court in the land!\", tensor(True)), ('Yeah, it is called the highest court in the land.', tensor(True)), (\"75 million? That's a lot of money! I wonder if they regret that decision. I'm surprised that FB is the most popular social media site in the world.\", tensor(True))]\n",
      "[(\"It's in Central America. It's the smallest country in the region.\", tensor(True)), ('I think it is one of the most popular foods in the world.', tensor(True)), (\"The top ranked player in the world for women's tennis is Serena Williams! She is the best player in the world!\", tensor(True)), ('162 games in a season, that\\'s a lot of baseball!  I\\'m surprised that the US Supreme Court has a basketball court on the top floor of the building, known as the \"highest court in the land\"', tensor(True)), ('270 million guns in the US. That is a lot of guns.', tensor(False)), ('100% original! he is the most influential skateboarder in history!', tensor(True)), (\"¡Claro! It's the most spoken language in the world. \", tensor(True)), ('7 feet is pretty tall! I wonder if he was the tallest player in the league?', tensor(True)), ('its the 11th most populous city in the US', tensor(False)), (\"I'm not the only one in the world who has to pay high rent.  New York is one of the most expensive cities in the world.\", tensor(True))]\n",
      "[('Buddhism is one of the oldest religions in the world, and it is the fourth largest religion in the world.', tensor(True)), ('17 year old girl struck out Babe Ruth, that is impressive, I wonder if she is still playing, I know that Babe Ruth is one of the most famous players in the history of the game', tensor(True)), ('100%! He is the best quarterback in the league right now.', tensor(True)), ('I did not know that.  I wonder if they have a name for it.  I know the Supreme Court building is the highest court in the land.  I wonder if they have a court on the top floor.', tensor(True)), ('I am not sure.  I am not a big fan of the stock market.  I think it is too risky.  I would rather just save my money in a savings account.', tensor(False)), ('I agree.  I think that is why it is one of the most popular activities in the world.  It is a way to learn and grow.  I think that is why it is so popular.  It is a way to learn and grow.', tensor(True)), ('He is the all-time leading scorer in nba history, and is the only player in nba history to be elected to the mvp award unanimously.', tensor(True)), ('I would love to go to a music festival. I think it would be the best experience of my life. ', tensor(True)), (\"I know, he was the only losing coach in the University of Kansas's history.\", tensor(True)), ('15 seasons as a starter. ', tensor(False))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=339, training_loss=1.5099244370924687, metrics={'train_runtime': 482.1455, 'train_samples_per_second': 4.212, 'train_steps_per_second': 0.703, 'total_flos': 1.910156281391232e+16, 'train_loss': 1.5099244370924687, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4434c38-76a7-4cef-873b-0377c874d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d95f59afc342f881efa07d8ce6ff03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Metrics:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7484ea44ca4a2fa609fc63da399f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Responses:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd2df89272948ec8d843b536023da0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Responses:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aacc1ff9eec479f9aefb2f214612e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Responses:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046f11182a2f47e99b4c37f478a5d09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Responses:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"I'm sure that's the case.  The NFL is the most popular sport in the US.  It's also the most popular sport in Canada.  I wonder if they have any rules about that.\", tensor(False)), (\"I think so. It's the most popular coffee in the world.\", tensor(True)), (\"343 Industries is still making Halo games, and they are the best in the business. I'm not sure if they are still making Halo 3, but it's still the best in the series.\", tensor(True)), ('1 billionth the size of the biggest star in our galaxy. I wonder if there is a star that is the size of the sun in our galaxy.', tensor(True)), ('I believe they do.  I know that the US Supreme Court has a softball field on the top floor of the building known as \"the highest court in the land\".', tensor(True)), (\"Yeah! It's one of the most popular games in the world.\", tensor(True)), ('I heard that they are the best band in the world', tensor(True)), ('100% they are the largest private employer in the world, they have a lot of money to throw around.', tensor(True)), (\"5th highest? Wow, I didn't know that. I guess he's not the highest paid player in the league.\", tensor(True)), (\"I know, he was the only losing coach in the University of Kansas's history.\", tensor(True))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_success_59': 0.8399999737739563,\n",
       " 'test_Appropriateness': 2.76,\n",
       " 'test_Relevance': 2.48,\n",
       " 'test_Content Richness': 2.8,\n",
       " 'test_Grammatical Correctness': 3.96,\n",
       " 'test_distinct': 0.5678233438485805}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics([], verbose=False, datasets={\"test\": test_dataset}, n=25, eval_quality=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5250aaa3-02de-4794-ba53-19d3e0c233d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"../models/mistral_FT_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "647989a0-c095-48eb-bb71-52f1b52a091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "#model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, cache_dir=os.getenv('CACHE_DIR'), device_map=\"auto\")\n",
    "#model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, cache_dir=os.getenv('CACHE_DIR'), padding_side=\"right\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.pad_token = '[PAD]'\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = PeftModel.from_pretrained(model, \"../models/mistral_FT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fb416-b4c7-4719-94c7-e8be23b7f673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gctg)",
   "language": "python",
   "name": "gctg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
