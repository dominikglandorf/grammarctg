{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f6c5a1-ee87-4b8f-9c8c-4208f80b8b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/scratch/dglandorf/cache...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c114ab791314a648761ae2e18a9f411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c0c1f5ce6a4476a2d2a8102eba5afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6464fee4b1406cb36fa67908fdb629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6b9679f42e4f009869fc175c6f2fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a120881a55ed4d31b0f3f4cf325352a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../source\")\n",
    "import helpers\n",
    "import data\n",
    "import models\n",
    "import api\n",
    "\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "\n",
    "client = OpenAI()\n",
    "egp = helpers.get_egp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54e6ee-9bf7-4f93-90c6-c7962ea7f612",
   "metadata": {},
   "source": [
    "Ask GPT4 for regular expressions of the corpus search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1a6f145-f930-4811-80d4-76cccf2f210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to find sentences with the singular reflexive pronouns 'myself', 'yourself', 'himself' and 'herself' for emphasis (category: PRONOUNS: reflexive) a text.\n",
      "What are Python regular expressions I should search for?\n",
      "Return a json array with basic regex: { \"search\": [regex1, regex2, ...] }.\n",
      "\\bhimself\\b\n",
      "\\byourself\\b\n",
      "\\bmyself\\b\n",
      "\\bherself\\b\n",
      "The best solution will be if you decide yourself what to do. \n",
      "\n",
      "I think it was the director himself who guided the actress through our wonderful school gardens to film the opening scene there. \n",
      "\n",
      "The food was delicious, especially the cake, which Sandra had cooked herself.\n",
      "1.0\n",
      "I myself, having been educated the hard way, would specifically insist on them getting the best possible school education. \n"
     ]
    }
   ],
   "source": [
    "# sample rule\n",
    "rule = egp.sample(1).iloc[0]\n",
    "# compose prompt\n",
    "prompt = f\"\"\"I want to find sentences with {\" \".join(rule['Can-do statement'].split(\" \")[2:]).replace(\".\",\"\")} (category: {rule['SuperCategory']}: {rule['SubCategory']}) a text.\n",
    "What are Python regular expressions I should search for?\n",
    "Return a json array with basic regex: {{ \"search\": [regex1, regex2, ...] }}.\"\"\"\n",
    "print(prompt)\n",
    "# query API\n",
    "messages = [{ \"role\": \"user\", \"content\": prompt}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",#\"gpt-3.5-turbo-1106\",#os.getenv(\"OPENAI_DEFAULT_MODEL\"),\n",
    "    messages=messages,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    n=1,\n",
    "    max_tokens=512,\n",
    ")\n",
    "#print(response.choices[0].message.content)\n",
    "\n",
    "matched_strings = set()\n",
    "all_expressions = set()\n",
    "strings_to_search = rule['Example'].split(\"\\n\\n\")\n",
    "\n",
    "for choice in response.choices:\n",
    "    all_expressions.update(json.loads(choice.message.content)['search'])\n",
    "for pattern in all_expressions:\n",
    "    print(pattern)\n",
    "\n",
    "for string in strings_to_search:\n",
    "    for pattern in all_expressions:\n",
    "        if re.search(pattern.replace(\"\\x08\", \"\").replace(\"\\x09\", \"\").replace(\"++\", \"+\"), string, re.IGNORECASE):\n",
    "            matched_strings.add(string)\n",
    "            break\n",
    "\n",
    "print(rule['Example'])\n",
    "\n",
    "print(len(matched_strings)/len(strings_to_search))\n",
    "\n",
    "other_rule = egp.sample(1).iloc[0]\n",
    "string_prob_not_to_match = other_rule['Example'].split(\"\\n\\n\")\n",
    "for string in string_prob_not_to_match:\n",
    "    for pattern in all_expressions:\n",
    "        if re.search(pattern.replace(\"\\x08\", \"\").replace(\"\\x09\", \"\").replace(\"++\", \"+\"), string, re.IGNORECASE):\n",
    "            print(string)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e00fa1-a333-49c6-9008-58d506f45141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt, stop=[], max_tokens=64, model=None):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model if model else \"gpt-4o\",\n",
    "        messages=[{ \"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        n=1,\n",
    "        stop=stop\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1d13fa-450e-4e02-8a13-9210db2a2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_skill(rule):\n",
    "    return f\"\"\"Learn this grammar skill from the description and the examples:\n",
    "{rule['guideword']}: {rule['Can-do statement']}\n",
    "Category: {rule['SuperCategory']}\n",
    "SubCategory: {rule['SubCategory']}\n",
    "CEFR Level: {rule['Level']}\n",
    "{f\"Lexical Range: {int(rule['Lexical Range'])}/3\" if not np.isnan(rule['Lexical Range']) else \"\"}\n",
    "Examples:\n",
    "{rule['Example']}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ea286d4-814d-4150-bda6-a0bfdc2bd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(rule):\n",
    "    prompt = f\"\"\"\n",
    "{describe_skill(rule)}\n",
    "\n",
    "Which words and combinations of words should I search for in a text to find other example sentences of this grammar pattern? Only output the words as a list.\n",
    "\"\"\"\n",
    "    response = get_response(prompt)\n",
    "    words = [res.replace(\"- \", \"\") for res in response.split(\"\\n\")]\n",
    "    words = [word for word in words if word != \"\"]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8f7c16-9e8d-41ec-9a44-a036802ac02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions(rule):\n",
    "    prompt = f\"\"\"\n",
    "{describe_skill(rule)}\n",
    "\n",
    "Create a checklist with questions that all necessarily need to be answered with \"Yes\" to judge whether that skill is used in a sentence. Only return the enumerated questions.\"\"\"\n",
    "\n",
    "    return get_response(prompt, max_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27942c56-9664-422e-80be-e0fbe3102fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_prompt(sentence, questions):  \n",
    "    return f\"\"\"\n",
    "Sentence:\n",
    "{sentence}\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Given the sentence, answer the given questions with either a clear \"Yes\" or \"No\". Only return the enumerated responses.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4666f5c-d915-4639-b6b0-cf202666cc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def judge(sentences, questions, verbose=True, max_positives=25, max_negatives=25):\n",
    "    positives = []\n",
    "    negatives = []\n",
    "    for probe in tqdm(sentences):\n",
    "        if verbose: print(probe)\n",
    "        response = get_response(detect_prompt(probe, questions))\n",
    "        if verbose: print(response)\n",
    "        if re.search(r\"\\bNo\\b\", response):\n",
    "            negatives.append(probe)\n",
    "        else:\n",
    "            positives.append(probe)\n",
    "        if len(positives) > max_positives: break\n",
    "        if len(negatives) > max_negatives: break\n",
    "    return positives, negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd583147-4fe6-4b96-9324-884bfaf6dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_corpus(words, sents):\n",
    "    results = {}\n",
    "    for sentence in tqdm(sents):\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            if bool(re.search(r\"\\b\" + re.escape(word.lower()) + r\"\\b\", sentence.lower())):\n",
    "                count = count/2 + 1 + word.count(' ') / 4 + int(word in sentence) / 8\n",
    "        results[sentence] = count\n",
    "\n",
    "    hits = [key for key, value in results.items() if value > 0]\n",
    "    sorted_sentences = sorted(hits, key=lambda x: results[x], reverse=True)\n",
    "    return results, sorted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76a22b24-f1c3-4f01-afce-848c7907365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "def get_trained_classifier(positive, negative, others, classifier, ratio=1, verbose=False):\n",
    "    dataset = data.get_dataset(positive, negative, others, models.bert_tokenizer, 64, ratio*len(positive)/len(negative), verbose=verbose) \n",
    "    train_dataloader, val_dataloader = data.get_loaders(dataset)\n",
    "    _, val_metrics = models.train(classifier, train_dataloader, val_dataloader, num_epochs=None, verbose=verbose, leave=not verbose)\n",
    "    return classifier, val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7aa001-914c-4859-b36e-798d17683aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:32<00:00,  8.16s/it]\n"
     ]
    }
   ],
   "source": [
    "sents = data.get_mixed_sentences(1000000)\n",
    "sents = set(sents) # remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d04daa-4cc9-4f1a-974d-5fbbe26ef72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_batches = 16\n",
    "batch_size = 256\n",
    "sentences = list(sents)\n",
    "encoded_inputs = models.bert_tokenizer(sentences[:12*max_batches*batch_size], return_tensors='pt', max_length=64, padding='max_length', truncation=True)\n",
    "encoded_inputs['sentences'] = sentences[:12*max_batches*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6881f6db-ae99-40d1-8fe2-3583bb75e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_candidates(classifier, positives, encoded_inputs, batch_size = 256, num_examples = 32000, max_positive=25):\n",
    "    shuffled_index = np.random.permutation(encoded_inputs['input_ids'].size(0))\n",
    "    for key, value in encoded_inputs.items():\n",
    "        encoded_inputs[key] = value[shuffled_index] if isinstance(value, Tensor) else [value[i] for i in shuffled_index]\n",
    "    \n",
    "    corpus_dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'])\n",
    "    corpus_dataloader = DataLoader(corpus_dataset, batch_size=batch_size, shuffle=False)\n",
    "    scores, tokens = models.score_corpus(classifier, corpus_dataloader, max_positive=max_positive, max_batches=num_examples//batch_size, threshold=0.5)\n",
    "    hits = list(zip(scores, tokens, encoded_inputs['sentences'][:len(scores)]))\n",
    "    subset = [(score, token, sample) for score, token, sample in hits if\n",
    "         score > 0.5 and not sample in positives]\n",
    "    return [sample for _, _, sample in subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3ffb02-3744-4b5b-bea5-1cde34f9085c",
   "metadata": {},
   "source": [
    "## Auto training flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba948c47-bc28-487a-8861-0279915e3d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORM: NEGATIVE: Can use the negative form with an increasing range of verbs.\n",
      "I didn't realise I had lost the ring till I was at home. \n",
      "\n",
      "I didn't trust him. \n",
      "\n",
      "[talking about a spare television] ? we had one in the garage that we did not use.\n",
      "[\"didn't\", 'did not']\n",
      "1. Does the sentence use the past simple tense?\n",
      "2. Is the sentence in the negative form?\n",
      "3. Does the sentence include a verb in its negative form?\n",
      "4. Is the verb used in the sentence part of an increasing range of verbs (i.e., not limited to basic verbs like \"be\" or \"have\")?\n",
      "5. Does the sentence make sense and convey a clear past action or state that did not happen?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e4733552ae424aaf75e7223c79e5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't realise I had lost the ring till I was at home. \n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I didn't trust him. \n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "[talking about a spare television] ? we had one in the garage that we did not use.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eace9803e1e42389ca61987d2b82e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/451036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I didn't dare look up at it as they advised because I did not want to hurt my eyes.\", 'My father made varsity in high school football but did not persue it when he moved to Canada.', 'She did not have to think to hard for a name for that one, lol.', 'okay thank you i did not know that, however I hike in the desert how big are the bears there?', 'I did not do anything that sophisticated.', 'That is very interesting, I did not know that.', 'With MySpace, people who did not go out much could reach out to others from the comfort of their own homes.', 'closer to town it seemed crowded but once you go out in the country, it did not seem crowded', 'that i did not know', 'I have heard of the grand rapids, but I did not know they were in Michigan, is it free to go there?']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afa9c2d37ab49d88d4c9aa3d311e5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She told Johnny that she had seen him walk up the trail earlier, but did not see him come back down, so she decided to come up to see if everything was okay.\n",
      "1. Yes\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "closer to town it seemed crowded but once you go out in the country, it did not seem crowded\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "Wow I did not know they lived so long.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not follow through my lessons\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Even giving them time to think about what to think about did not help.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know they were founded in the 1940s by the McDonalds.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "They did not do that, but they yelled at me a lot\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Oh I did not know that do you know when they started?\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Although it did not look unappealing, he was not too fond of his short hair, and desired to grow it out one day.\n",
      "1. Yes\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "My father made varsity in high school football but did not persue it when he moved to Canada.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Hmm, no I did not.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "I did not know that, I knew it was best to cheat children as young as possible to do it.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "He did not go to collage, and got a deal with Motown records, which dropped him in 2009, then he signed with atlantic records\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "She did not have to think to hard for a name for that one, lol.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "wow, i did not know that.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "The girl had tried to find her family by asking for help from strangers, but did not remember the names of her parents and could only vaguely remember that she had a grandfather named Ibraham.\n",
      "1. Yes\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know he wrote that\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not do anything that sophisticated.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "i did not like the remake with Robin Williams, he did not have the dignity of Fred MacMurray to pull it off\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Wow, I did not know the recipe was switched!\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know that either.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Oh, that explains why he did not do much after the label, that is truly sad\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know you could make them by hand.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I have heard of the grand rapids, but I did not know they were in Michigan, is it free to go there?\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "Oh really, I did not know that.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not realize he was not only a singer-songwriter, but also guitarist, actor and author.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know that.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know that, I have never been there, my only experience of Louisana is simply a few restaurants.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "Wow, I did not know that!\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "His sister did not have a computer.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "yeah i remember in school we used I guess acrylic paint since it did not have an order to it\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "That may be why, I did not know he changed his name, that is almost always a bad move!\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know how hard of a tasks this would be.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "sometime they do if  you did not complete the required curriculum.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "Wow i did not know that, husky's are really smart too they can really surprise people\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "that i did not know\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "That is very interesting, I did not know that.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Yeah makes me feel old too lol I did not realize it was that far back\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "During one of his lecture tours in 1843, Douglass was nearly beaten to death by an angry mob, who did not agree with his message of abolition.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "okay thank you i did not know that, however I hike in the desert how big are the bears there?\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I did not know he did it live back then!\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "did not expect that\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "78\n",
      "0.21666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7036705017089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:02,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.675025686621666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6672582626342773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:01,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6552436202764511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6406636238098145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6363911479711533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6161022782325745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [00:00<00:01,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.616473451256752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5909160375595093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [00:01<00:01,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5983719080686569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5770623087882996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [00:01<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5814603567123413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.537670910358429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [00:01<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5658413618803024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.512141764163971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [00:01<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5517886132001877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.47877785563468933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:01<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5384968221187592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.44390445947647095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5265617296099663\n",
      "{'accuracy': 0.742, 'f1': 0.0, 'precision': 0.0}\n",
      "78\n",
      "0.21666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7541539072990417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:01,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6947223246097565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7064414620399475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:01,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6841177046298981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6765459179878235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6771922409534454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6534072160720825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6726928353309631\n",
      "{'accuracy': 0.753, 'f1': 0.0, 'precision': 0.0}\n",
      "78\n",
      "0.21666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7834492921829224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:01,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7649252116680145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7444173693656921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:01,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7410848885774612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.727493405342102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7153157889842987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7150368094444275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [00:00<00:01,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6942311823368073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6923277378082275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [00:01<00:01,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6741148680448532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6608845591545105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [00:01<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6539289206266403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6502724885940552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [00:01<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6386194825172424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.639548659324646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [00:01<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.626449853181839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6116395592689514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:01<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6149486154317856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.58664470911026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6039915680885315\n",
      "{'accuracy': 0.784, 'f1': 0.087, 'precision': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▏                                                                                                                                 | 6/192 [00:02<01:02,  2.97it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64812d9945ac41c48fbd6bef76a33b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personally, I am interested in LOL, aka laughing out loud, I get a lot of kicks out of laughing.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "yes a lot in Huntington Beach, but i dont like it there, for me the best place is The gold coast region in Australia :D\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "I want to ride a horse down it and pretend I'm a cowgirl lol\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "LOL I love the description.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "That's not a bad reason to make up that story lol.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "i dont know, but do know it was built to be a practical short route between san frnacisco to san fransico bay\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "I've been reading all the information I need to write it.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "I can't say I'm a big fan of them lol\n",
      "1. No\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "Im not sure but  Myron Scott is credited for naming the car after the type of small warship\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "I'm not positive, but in many countries you have to go to school for many years to get the title of veterinarian.\n",
      "1. No\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. No\n",
      "Now, the trading city, nicknamed the “door of the desert”, is the location for another blockbuster – a complex of four linked solar mega-plants, which, alongside hydro and wind, will help provide nearly half of Morocco’s electricity from renewables by 2020 with, it is hoped, some spare to export to Europe.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "The German world number 29 improved in the second set and missed a chance to take a 3-2 lead when he wasted his only break point of the match.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "It was created by John de Mol Jr, and it's the best reality show ever!\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "Stephen Hawking was an amazing man.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "It is one of the most popular foods in the world, I did eat it everyday in college lol.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "hatha yoga and raja yoga is my fevourite\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "Ahahah... you miss her point for sure.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "Math mostly, lol.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "lol!\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "I chopped cotton every summer from when I was 12 until I was 18, lol.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "That I have no idea about...lol.\n",
      "1. No\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "i dont seem to know myself, looks like a charitable organization i s a none profit organization\n",
      "1. No\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "It easily causes secondary infections to breed!\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "But, in my experience, the majority of prisoners want to change, and we must do what we can to help to facilitate that.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. No\n",
      "Oh really dont hear that often.\n",
      "1. No\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "Right, it's to discuss the new factory in France.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "0.0\n",
      "78\n",
      "0.1780821917808219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6924113631248474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:02,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6533315479755402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6383043527603149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:02,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6264836639165878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5941591858863831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6060847789049149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5571304559707642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [00:01<00:01,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5888864398002625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5307057499885559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [00:01<00:01,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5731925964355469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5079308748245239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [00:01<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5597813725471497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.47419461607933044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [00:01<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5490414053201675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.44479086995124817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [00:01<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5408432930707932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.40977975726127625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:02<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.534480482339859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.38335227966308594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.529229037463665\n",
      "{'accuracy': 0.795, 'f1': 0.0, 'precision': 0.0}\n",
      "78\n",
      "0.1780821917808219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8156377673149109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:02,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7227945476770401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7352733612060547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:01,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6889823228120804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6761225461959839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6605324745178223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6377943754196167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [00:00<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6392902284860611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6089059710502625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [00:01<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6217420697212219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5719513297080994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [00:01<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6058507412672043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5494544506072998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [00:01<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5926124453544617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.98it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5160545706748962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [00:01<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5821046382188797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.49039819836616516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:02<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5731649845838547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4764280617237091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5656691789627075\n",
      "{'accuracy': 0.795, 'f1': 0.0, 'precision': 0.0}\n",
      "78\n",
      "0.1780821917808219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7232652902603149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:02,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6784507185220718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6780065298080444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.646072655916214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6435288786888123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6205509752035141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6052405834197998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [00:00<00:01,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5987463891506195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5759108066558838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [00:01<00:01,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5804248452186584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5553861856460571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [00:01<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5659065395593643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5222958326339722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [00:01<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5553257167339325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4920880198478699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [00:01<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5474540442228317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4799840748310089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:02<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5407114624977112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4417586326599121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5343418419361115\n",
      "{'accuracy': 0.812, 'f1': 0.0, 'precision': 0.0}\n",
      "78\n",
      "0.1780821917808219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6482275724411011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:02,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6136747598648071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6288759708404541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5908813625574112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6029932498931885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5688029676675797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5809575319290161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [00:00<00:01,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5486064702272415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.55214923620224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [00:01<00:01,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5300237536430359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5408415198326111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [00:01<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5118698626756668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5182812809944153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [00:01<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4963161051273346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.48711928725242615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [00:01<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.47917646169662476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4691562056541443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:02<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4632137268781662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.45345306396484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.44689448177814484\n",
      "{'accuracy': 0.829, 'f1': 0.0, 'precision': 0.0}\n",
      "78\n",
      "0.1780821917808219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6958546042442322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:00<00:02,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6390906721353531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6375834345817566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:00<00:01,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.6079714000225067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6163535118103027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [00:00<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5876949578523636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5786628127098083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [00:00<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5685053765773773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5616912245750427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [00:01<00:01,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.547991156578064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5405859351158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [00:01<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5301673859357834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5025865435600281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [00:01<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.515660896897316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5042133927345276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [00:01<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5035492405295372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4777926802635193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:02<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.49381622672080994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.44165727496147156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.4872833862900734\n",
      "{'accuracy': 0.821, 'f1': 0.0, 'precision': 0.0}\n",
      "78\n",
      "0.1780821917808219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.36it/s]\u001b[A\n",
      "                                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7644012570381165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m     35\u001b[0m classifier \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mRuleDetector(models\u001b[38;5;241m.\u001b[39mbert_encoder)\u001b[38;5;241m.\u001b[39mto(models\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 36\u001b[0m classifier, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mget_trained_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegatives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mothers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.\u001b[39m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mget_trained_classifier\u001b[0;34m(positive, negative, others, classifier, ratio, verbose)\u001b[0m\n\u001b[1;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_dataset(positive, negative, others, models\u001b[38;5;241m.\u001b[39mbert_tokenizer, \u001b[38;5;241m64\u001b[39m, ratio\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(positive)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(negative), verbose\u001b[38;5;241m=\u001b[39mverbose) \n\u001b[1;32m      4\u001b[0m train_dataloader, val_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget_loaders(dataset)\n\u001b[0;32m----> 5\u001b[0m _, val_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classifier, val_metrics\n",
      "File \u001b[0;32m~/grammarctg/experiments/../source/models.py:178\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, num_epochs, lr, criterion, optimizer, verbose, leave)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_dataloader:\n\u001b[1;32m    177\u001b[0m     input_ids, attention_mask, labels \u001b[38;5;241m=\u001b[39m (batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m--> 178\u001b[0m     outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     model\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(outputs, labels)\n\u001b[1;32m    180\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.11.2/x86_64/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/grammarctg/experiments/../source/models.py:85\u001b[0m, in \u001b[0;36mRuleDetector.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[0;32m---> 85\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(outputs\u001b[38;5;241m.\u001b[39mhidden_states, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.11.2/x86_64/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.11.2/x86_64/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.11.2/x86_64/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.11.2/x86_64/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/apps/nss/gcc-8.2.0/python/3.11.2/x86_64/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py:365\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[0;32m--> 365\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    368\u001b[0m new_context_layer_shape \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sample a rule\n",
    "rule = egp.sample(1).iloc[0]\n",
    "print(f\"\"\"{rule['guideword']}: {rule['Can-do statement']}\n",
    "{rule['Example']}\"\"\")\n",
    "# ask GPT for search strings\n",
    "words = get_words(rule)\n",
    "print(words)\n",
    "# ask GPT for detection questions\n",
    "questions = get_questions(rule)\n",
    "print(questions)\n",
    "# do a sanity check of the questions with the given examples\n",
    "positives, negatives = judge(rule['Example'].split(\"\\n\\n\"), questions)\n",
    "assert len(negatives)==0\n",
    "# Find candidates in corpus\n",
    "results, sorted_sentences = search_corpus(words, sents)\n",
    "others = list(sents.difference(set([key for key, value in results.items() if value == 0])))\n",
    "print(sorted_sentences[:10])\n",
    "# judge candidates\n",
    "positives = []\n",
    "negatives = []\n",
    "\n",
    "candidates = sorted_sentences[:50]\n",
    "#random.shuffle(candidates)\n",
    "candidates = list(set(candidates).difference(set(positives+negatives)))\n",
    "new_positives, new_negatives = judge(candidates, questions)\n",
    "assert len(new_positives) > 5\n",
    "positives = positives + new_positives\n",
    "negatives = negatives + new_negatives\n",
    " \n",
    "# iteratively train classifier\n",
    "metrics = {\"precision\": 0.}\n",
    "iterations = 0\n",
    "while metrics['precision'] < 0.8 and iterations < 5:\n",
    "    iterations += 0.2\n",
    "    classifier = models.RuleDetector(models.bert_encoder).to(models.device)\n",
    "    classifier, metrics = get_trained_classifier(positives, negatives, others, classifier, ratio=3, verbose=True)\n",
    "    print(metrics)\n",
    "    if metrics['precision'] == 0.: continue\n",
    "    # get new candidates\n",
    "    new_candidates = get_new_candidates(classifier, positives, encoded_inputs)\n",
    "    assert len(new_candidates) > 5\n",
    "    iterations += 0.8\n",
    "    # retrain on new candidates\n",
    "    new_positives, new_negatives = judge(new_candidates, questions)\n",
    "    precision = len(new_positives) / (len(new_positives)+len(new_negatives))\n",
    "    print(precision)\n",
    "    if precision > 0.75: break\n",
    "    \n",
    "    positives = positives + new_positives\n",
    "    negatives = negatives + new_negatives\n",
    "\n",
    "if metrics['f1']>0.75:\n",
    "    models.save_classifier(classifier, rule['#'], \"auto_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea6b6340-bf05-405c-a311-fc289d1ac922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When shall we have a coaching period?',\n",
       " 'When shall we sign the contract, Mrs. Brown?',\n",
       " 'Where shall we sit?',\n",
       " 'What shall we do this weekend?',\n",
       " 'When and where shall we meet?',\n",
       " 'And by the way, what time shall we get to Nanchang?',\n",
       " 'When shall we go?',\n",
       " 'What shall we do when we find a shortage in the shipment?',\n",
       " 'So, where shall we have our dinner?',\n",
       " 'Where shall we park our car?',\n",
       " \"I haven't been in his house for several weeks.When shall we start?\",\n",
       " 'Where shall we go?',\n",
       " \"We're sleeping here tonight, Jason.\",\n",
       " 'A bunch of us are going there for dinner tomorrow night.How about coming with us?',\n",
       " 'Jane, yesterday, I got a call from the local police station to pick up Biggie.',\n",
       " 'I hope to go to one one day.',\n",
       " 'And I hope I can enter your school one day.',\n",
       " \"Mom, I don't want to bathe today.\",\n",
       " \"We'll have them worked out by this evening and let you have them tomorrow morning.\",\n",
       " 'It lasts 4 hours, from 10:00 to 14:00',\n",
       " 'OK, I want 5 tickets for the 9 p.m. showing tonight.',\n",
       " 'About ten.another thing is that I want an appointment with the customer at Changing hotel at three thirty this afternoon.please help me phone the customer so we can confirm now.',\n",
       " \"Don't forget to perform your duty next time, ok?\",\n",
       " 'What can I do for you this morning?',\n",
       " 'Thank you for coming tonight, Mrs. Webber.',\n",
       " 'Welcome to IBA, what can I assist you with today?',\n",
       " 'A Lufthansa jumbo jet nearly collided with another plane at John F. Kennedy International Airport Monday after an EgyptAir flight apparently veered into its path just as the jet barreled down the runway, according to air traffic controller tapes.',\n",
       " \"It's only 12:30.\",\n",
       " 'How about we go to the flea market today?',\n",
       " 'Could I reserve a table for Saturday, September 16th at 8: 00 p. m.?',\n",
       " 'Can I get on the big rides tomorrow?',\n",
       " \"I'm leaving tomorrow.\",\n",
       " 'I have a class tomorrow.',\n",
       " \"I guess I'll have to be your mother for today.\",\n",
       " 'He went to the tryouts at school the next day.',\n",
       " 'The campus radio station is willing to let you have five minutes tomorrow morning at seven to outline your plans for the year.',\n",
       " 'I plan on owning Ferrets one day, truly interesting creatures.',\n",
       " \"OK. Is it possible to leave my luggage here until I'm ready to leave this afternoon?\",\n",
       " 'Sounds interesting, have you ever been a teacher before?',\n",
       " 'Must have been early on in the 20th Century.',\n",
       " \"Owner operators own but do not drive, owner drivers own and drive, company drivers are hired to drive but don't own the trucks\",\n",
       " 'The jungle camp offers a free meal a day and a plastic roof over their heads so many decide to endure the basic conditions for a few extra months, rather than potentially jeopardize their asylum bid by working illegally.',\n",
       " 'Oh wow, I had never heard of that one before, I might seek out a polar desert for my next trip!',\n",
       " \"The rest are categorized according to potential and interest.You can see we've got our hot stack, our warm stack, our lukewarm, and our cold but not dead stack.\",\n",
       " 'the group consisted of Michael \"Mike D\" Diamond (vocals, drums), Adam \"MCA\" Yauch (vocals, bass) and Adam \"Ad-Rock\" Horovitz (vocals, guitar).',\n",
       " ' The Beastie Boys have sold 26 million records in the United States and 50 million records worldwide,',\n",
       " 'I have not been to one before but I sure would love to.',\n",
       " 'I have never had a bank account before.',\n",
       " \"I can't say that I have in real life but chalk has greater resistance to weathering and slimping than clays\",\n",
       " 'We Can Do It was the brainchild of Felicia Nordström, a bar worker who says she was fed up with bearded beer snobs telling her: “What do you know about beer, sweetie?” She approached FemAle and they teamed up with Ocean, a local independent micro-brewery.',\n",
       " 'Have you ever ridden on a moped, also known as small motorcycle?',\n",
       " \"Well, I sympathize with your problem, but frankly, I don't think there is anything anyone can do for you.\",\n",
       " \"I haven't got much.\",\n",
       " \"Well the Chevrolet Camaro is a car produced by Chevrolet, I'm sure you have heard of it.\",\n",
       " 'I agree, but she seems to be doing ok, even when she signed with the label Big Mashine Records as the youngest artist they had ever signed for her first album, I believe,',\n",
       " 'Sorry to have smoked in your room.',\n",
       " 'I bet she has, you really should be trained to teach it.',\n",
       " \"Yeah, and being active in sports helps a lot to keep up one's health.\",\n",
       " 'The other thing is once you have been treated you could go through a community health service which would provide outpatient treatment and more!',\n",
       " 'After you have your great idea, then you can set up shop by registering a domain name, creating a website, an email address, and a hosting service.',\n",
       " \"that's one way to improve your reading comprehension looking up word we all do from time to time\",\n",
       " 'Many economic and social changes have resulted in both men and women of all ages turning to the streets of Los Angeles.',\n",
       " 'You have explained clearly.',\n",
       " 'In this pamphlet it says that the minimum amount for deductibles is $ 2000. what does that mean exactly?',\n",
       " 'Hey, how is it going?',\n",
       " 'Are you seasick?',\n",
       " 'Music associated with Christmas is thought to have its origins in 4th century Rome!',\n",
       " \"Weren't you supposed to get a report card sometime this past week?\",\n",
       " 'What other interesting things have you learned from this documentary?',\n",
       " 'The United States government introduced the G.I.',\n",
       " 'I sent my driver to pick you up, is he there?',\n",
       " 'Colored pigment into the skins dermis is the modern process via a tattoo needle',\n",
       " 'Ok, good luck, Jessica.',\n",
       " 'Oh ok, Is there any other things you know about classical music?',\n",
       " 'And London?',\n",
       " 'What games?',\n",
       " '\"We are playing Hide and Seek,\" said Robert, my brother\\'s best friend.',\n",
       " 'One way trip or round trip?',\n",
       " 'Novels are my favorite books to read',\n",
       " 'Oh ok. Do you have to be careful of small vehicles on the road?',\n",
       " 'I have never understood how vision works can you explain a little?',\n",
       " 'Have you ever been to Jamaica?',\n",
       " 'Do your siblings have red hair?',\n",
       " 'When, exactly do you need to leave?',\n",
       " 'If you see him a third time, and if he follows you again, then I think we should go to the police.',\n",
       " 'Kinda weird though, huh?',\n",
       " 'These days it is much less common to be orphaned in the US or other developed countries, I think.',\n",
       " 'What do you think about giant pandas?',\n",
       " 'Sherlock Holmes refers to himself as a \"consulting detective\" in the stories.',\n",
       " \"You don't follow the Olympics?\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51603778-56bd-499b-8105-4b4049aca274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.783, 'f1': 0.0, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.797, 'f1': 0.0, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.754, 'f1': 0.0, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.797, 'f1': 0.222, 'precision': 0.333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                                                     | 1/192 [00:00<01:49,  1.74it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8c228ef63d4f53bb69225449130749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yea Porsche are high performance sports cars\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "Um, I mean, she didn't tell me anything like that.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Another greatest of all time is Whitney Houston she is another worldwide artist I hated to see go.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "I try to keep it at or under 10% of calories, which is hard given how much sugar is in many foods.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "The population there has red hair 2-6% of the time.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "820 University, Box 4348, Chicago, Illinois.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I already have a standard meeting on Thursdays at 9:30 a. m. How about Wednesday afternoon at 2\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Put the eye-drop into your right eye 4 - - 6 times a day, 1 - - 2 drops each time.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "It takes only one day and you could experience almost all the famous spots in the city, I don't think you would like to miss it.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "Now the deadlines are near, and I still have not finished all of my projects.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I haven't watch ed all of it, you have to pay for all but the first episode!\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. No\n",
      "5. Yes\n",
      "I guess it's a growing industry with the development of smartphones on faster connections, everyone are on the internet all the time aren't they!\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "So thats why they sell them for so much because that person can make a good product profit off of them they can go for 750,000 the sweaters better keep my whole family warm lol.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "Ok. China is about the same size as Canada and the united states and it has a population of about 1.3 billion, making it the latest country in the world by population.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "The test ended 10 minutes ago, and you weren't there to take it.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "﻿Coal is likely to rival oil as the world’s biggest source of energy in the next five years, with potentially disastrous consequences for the climate, according to the world’s leading authority on energy economics.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Not only did they have bats and gloves, but also equipment for all kinds of sports.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Yea they are a big love symbol and represent beauty and all that\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "I like them ok, but unfortunately they are not my favorite pet, even though there are more than 70 different breeds.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "She'd better not start crying like she usually does.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "There are very few things a parent can count on when it comes to air travel these days, but one of those things was always the ability to board first to get your children settled in and all of their needs met before the throngs of people board the plane, said Hanni in an e-mail to CNN.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Can you believe it naturally occurs in only 1-2% of human population?\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "We went all the way to the top.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Data collected by Ofcom (the independent regulator and competition authority for the UK communications industries) suggests that, between November 2012 and January 2013 in the UK, 280 million music tracks were digitally pirated, along with 52 million TV shows, 29 million films, 18 million ebooks and 7 million software or games files.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I'm afraid, ma'am, you have to pay U. S. $ 100 since you lost the key.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "But why would a guy be selling new video cameras for twenty dollars?\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "“Legislative measures are limited.” \n",
      "When the children have missed starting school at five years old, it is a race against time to prevent them from growing up without an education.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I'd love to, but my mother asks me to go home before 11:00 every night.\n",
      "1. Yes\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.818, 'f1': 0.0, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [00:01<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.779, 'f1': 0.0, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.766, 'f1': 0.1, 'precision': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                                                    | 3/192 [00:01<01:13,  2.58it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbadfd66b3a43d99db45b46c9db625f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yea they took the wrong side in the civil war there.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I guess they were innovative with their hair too!\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Apparently, there was a huge computer room we can study in.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I figured they were French in origin.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Maybe we could go to the jazz concert at the school auditorium instead.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I mean, if you had said that to me five years ago, I would have thought that you were absolutely mad.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Why would they recall something related to floor mats.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Honey, we're in the museum now.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "They must have practiced a lot.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "They had been married for 20 years, but had never had a vacation.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "What kind of temperament do they have?\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "its to explore whether they are romantically or sexually compatible.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "I think they went to Mexico, but I'm not sure.It ' s a bad thing to return home to.They ' ll come home from their trip, and they'll see half their house burned.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "I wonder how many of us don't even realize our bodies are telling us that we shouldn't eat certain things.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Just because they wanted to foster my loveof reading and it seemed better than doing what other teenaged kids were doing I suppose\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "Obama said Friday that NATO leaders had called passage of the treaty -- which, among other things, would restart mutual nuclear inspections and limit the arsenal in the two countries -- critical to European and global security.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "They need someone for the empty bedroom.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Depending on future greenhouse gas emissions, sea levels will rise an average of 40 –62 cm by 2100.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I know, I wish I could keep a giant panda as a pet even though they are native to China.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Does that mean you're going to take my advice?\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Alvin asked his brother Levi one night, as they were lying down in bed around eleven at night.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "There was no reason to make us wait at all.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I had not known that, there is so much that we don't initially see.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "Crazy they can see so well in the dark.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "That was a bit terrifying for both of us.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "The rebels announced Friday they had written U.N. Secretary General Ban Ki-moon, requesting an investigation and demanding that any individuals found to be involved in the deployment of chemical weapons in Syria be held accountable for these crimes.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Now they are less about rebelling and more about just having fun.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.741, 'f1': 0.087, 'precision': 0.125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                                                     | 1/192 [00:00<01:50,  1.73it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccfe2210b9d4bf9934adf935c4d7c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, he isn't really bad-tempered.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I have also, the inflammation, swelling, and pain was terrible.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "Cattle were brought to Japan from China way back in the day.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "It's crazy to think that the oldest tattooed discovered was from before 3000 BC!\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "In 2007, the Bloomberg-appointed health board adopted a regulation that forced restaurants to all but eliminate the use of partially hydrogenated vegetable oils and spreads, the main sources of trans fats in the U.S. diet.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "that's a nice cruiser-type motorcycle, i like Honda motorcycles\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Please come back next week.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "what isspecial about pugs, are they super atheletic or anything?\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "I play tennis on the weekends, I love it!\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I used to be a makeup artist but I hated it, so now I'm back in the restaurant industry.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I know, it's so delicious that I could really use some right now.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Yes, the bus doesn't go there directly.You have to take the No.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "Well, no, no.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "I am very thankful, I couldn't imagine trying to put something directly on my eye.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "no, they just needs to make sure the trucks are drivable, they inspect them for issues relating to safe operation like is the check engine light on, are the rites good, etc\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. No\n",
      "5. No\n",
      "No, that's Jenny's husband, Charlie.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "The history of it dates back to 1764!\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Yes most classical music is played on the piano or violin, Buy my favorite is the violin,  Most violins have a fully hollow wooden body and sound delightful.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "When he told his dad what he paid for it, he thought his dad was going to be mad, but he just said, \"That's okay, son.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "The origins of novels are all the way back in classical Greece.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "This government is capable of turning back the clock.” \n",
      "Being a wolf advocate is not easy.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "With all the craziness in the healthcare field these days, trying to figure out Medicare, Medicaid, Veterans Administration, etc.. it seems like new dr's are dwindling.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "Especially Chris Evans, some have been doing this since MCU started in 2007.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "Yes it is, better than I expected it would be.The presenters have been first rate.Is this the first conference you've been to?\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "Only a bag, a sleeping bag and some warm clothing.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "I'm not sure what he looks like, I guess the only one I've paid attention to is the lead singer - what's his name?\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "No, I think I would hate it.\n",
      "1. Yes\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8, 'f1': 0.0, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.765, 'f1': 0.0, 'precision': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8, 'f1': 0.105, 'precision': 0.333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▍                                                                                                                                    | 2/192 [00:00<01:22,  2.30it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a713266e425047d2a83f39ba6c89027e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But I think you can fly on Northwest 212 to Tokyo and they have a connecting flight on Japan Airline 123 to Auckland, New Zealand's gateway city.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I think that a vegetarian diet is often thought to be lower in fat and cholesterol.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Yes there is skiing and you've also got the lake that forms half of Vermont's western border with New York.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Why not buy a guidebook to the city?\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "The book is really good.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "If wealthy Americans talk about the unique challenges that come with their wealth, people often dismiss their experience.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "taco predates the arrival of the Spanish in Mexico, there is anthropological evidence that the indigenous people living in the lake region of the Valley of Mexico traditionally ate tacos filled with small fish\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "Do you know much about bipolar disorder, it used to be known as manic depression that causes depression and elevated mood.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "You will be amazed how full you will be after eating the smaller servings and your pocketbook will also thank you.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "No it's based off the entire series called A Song of Ice and Fire, I guess they just chose to go with the name of the first book.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "That looks like an interesting book.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I'm not a big fan of musicals either, but I saw one a few years ago called The Book of Mormon.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "Vitamin c also contains antioxidant is a molecule that inhibits the oxidation.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "The conflict in Vietnam was raging, the country was reeling from the assassinations of John F. Kennedy, and his brother Senator Robert Kennedy, and Martin Luther King Jr. Nixon's victory indicated the country was ready for a conservative leadership during these tough times.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "My favorite is Rosa Bonheur, shes considered to be the most famous female painters of the 10th  century.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "Yes I actually worked at a Neapolitan pizza place that used Italian ingredients and made it in the tradition of Naples Italy.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Does it run in your family, or are you the only one that has it?\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "The results of the research are based on an analysis of 343 peer-reviewed studies from around the world – more than ever before – which examine differences between organic and conventional fruit, vegetables and cereals.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I don't know much about it in India, however in Japan the most popular types are Pure Land Buddhism,  Nichiren Buddhism, Shingon Buddhism and Zen.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Buddhist music is music for Buddhist ceremony or meditation\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Other countries have landed unmanned missions to the Earth's largest satellite, but to date, no other person has walked on the moon since then.\n",
      "1. No\n",
      "2. No\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "In other words, do not go trekking near the border that separates the Indian and Pakistani controlled parts of J&K.\n",
      "1. Yes\n",
      "2. Yes\n",
      "3. Yes\n",
      "4. Yes\n",
      "5. Yes\n",
      "The Rio Grande sector, where most of the immigrant children are turning themselves into the border patrol, currently has 3,000 border patrol agents covering 320 miles of land and 250 miles of water, which equates to 5.4 agents per mile.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "Poicephalus mesotypus – This parrot has an orange vest and originates from Cameroon in the southwest region of Chad and northeastern and eastern Nigeria\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. No\n",
      "Anything that has salt, chili peppers those are very aztec ingredients!\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. No\n",
      "5. Yes\n",
      "The findings seem to show that children born in the early months of the school year enjoy a double “autumn advantage” – they are already known to have an academic advantage and, now, they also appear to be better equipped for sport, too.\n",
      "1. Yes\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "That is the one that can lead to death.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n",
      "I am a vegetarian, but don't know much about the history of this diet.\n",
      "1. No\n",
      "2. No\n",
      "3. No\n",
      "4. Yes\n",
      "5. Yes\n"
     ]
    }
   ],
   "source": [
    "# iteratively train classifier\n",
    "\n",
    "iterations = 0\n",
    "while metrics['f1'] < 0.75 and iterations < 5:\n",
    "    iterations += 0.2\n",
    "    classifier = models.RuleDetector(models.bert_encoder).to(models.device)\n",
    "    classifier, metrics = get_trained_classifier(positives, negatives, others, classifier, ratio=3, verbose=False)\n",
    "    print(metrics)\n",
    "    if metrics['precision'] == 0.: continue\n",
    "    # get new candidates\n",
    "    new_candidates = get_new_candidates(classifier, positives, encoded_inputs)\n",
    "    assert len(new_candidates) > 5\n",
    "    iterations += 0.8\n",
    "    # retrain on new candidates\n",
    "    new_positives, new_negatives = judge(new_candidates, questions)\n",
    "    if len(new_positives) / (len(new_positives)+len(new_negatives)) > 0.75: break\n",
    "    \n",
    "    positives = positives + new_positives\n",
    "    negatives = negatives + new_negatives\n",
    "\n",
    "if metrics['f1']>0.75:\n",
    "    models.save_classifier(classifier, rule['#'], \"auto_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "925f2fe6-f33b-46cb-935b-904218ad58fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_positives) / (len(new_positives)+len(new_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "a300e8c1-8ead-4ed5-ab1f-0a64e4d440f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I've been\",\n",
       " 'I have been',\n",
       " \"She's been\",\n",
       " 'She has been',\n",
       " \"He's been\",\n",
       " 'He has been',\n",
       " \"We've been\",\n",
       " 'We have been',\n",
       " \"They've been\",\n",
       " 'They have been',\n",
       " \"You've been\",\n",
       " 'You have been',\n",
       " 'for',\n",
       " 'since']"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words += [c[0] + \" \" + c[1] for c in combinations(words, 2) if c[0].count(' ')==0 and c[1].count(' ')==0] + [c[1] + \" \" + c[0] for c in combinations(words, 2) if c[0].count(' ')==0 and c[1].count(' ')==0]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "3362cb5d-1211-4333-9e60-88aed59bb615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "b517effb-78da-47ee-b189-b765019336e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataset\n",
    "\n",
    "output_path = '../data/auto_annotated_corpus.json'\n",
    "instances = pd.DataFrame(columns=['#', 'sentence', 'positive']) if not os.path.exists(output_path) else pd.read_json(output_path)\n",
    "instances['positive'] = instances['positive'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "018749d7-19ea-4e99-b28a-1e19cf2f5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in positives:\n",
    "    new_row = pd.DataFrame({'#': [rule['#']], 'sentence': [sentence], 'positive': [False]})\n",
    "    instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "for sentence in negatives:\n",
    "    new_row = pd.DataFrame({'#': [rule['#']], 'sentence': [sentence], 'positive': [False]})\n",
    "    instances = pd.concat([instances, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "eb8deace-cda9-4c78-9ddb-063c64fb1683",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances.to_json(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050535d-f39c-4288-a73d-7973198b7b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
