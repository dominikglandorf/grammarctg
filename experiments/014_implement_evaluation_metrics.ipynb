{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8174bab-e824-4ea1-a9bd-33410a8ad753",
   "metadata": {},
   "source": [
    "# Exp014: Evaluation metrics\n",
    "The goal of this experiment is to evaluate the three tasks on several quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac47bf04-c3cc-450e-8aa0-bd509b1efd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/dglandorf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.util import ngrams\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../source')\n",
    "import models\n",
    "import helpers\n",
    "import api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de06d7-8471-453e-a383-4950ee85f130",
   "metadata": {},
   "source": [
    "Let's start with distinctiveness. This metric should be calculated for the same constraints but for different contexts to make sure that the model does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8ce304-7026-478c-9ee6-88cdea3f0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distinct_n(texts, n=2):\n",
    "    if isinstance(texts, str): texts = [texts]\n",
    "    n_grams_per_text = [list(ngrams(nltk.word_tokenize(text), n)) for text in texts]\n",
    "    n_grams = helpers.flatten_list_of_lists(n_grams_per_text)\n",
    "    unique_n_grams = len(set(n_grams))\n",
    "    total_n_grams = len(n_grams)\n",
    "    return unique_n_grams / total_n_grams if total_n_grams > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498dd60-36f6-4e9a-a732-b5a49f9b3122",
   "metadata": {},
   "source": [
    "Add an easy way to summarize skill detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac047b1f-d44b-49d1-9d38-3b7a0288daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarDetection():\n",
    "    def __init__(self, dir=\"corpus_training\", skill_nrs=None):\n",
    "        if skill_nrs is None: skill_nrs = [int(name.replace(\".pth\",\"\")) for name in os.listdir(f\"../models/{dir}\")]\n",
    "        self.classifiers = {nr: models.load_classifier(nr, 'corpus_training') for nr in skill_nrs}\n",
    "\n",
    "    def score_texts(self, sentences):\n",
    "        return {nr: models.probe_model(classifier, sentences) for nr, classifier in self.classifiers.items()}\n",
    "\n",
    "    def constraint_satisfaction(self, text, constraints):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        hits = []\n",
    "        for nr in constraints:\n",
    "            outputs = models.probe_model(self.classifiers[nr], sentences)\n",
    "            hits.append(sum(outputs[0]>0.5).item() / len(sentences))\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f08ca91c-942a-4587-9106-81f6fe50467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = GrammarDetection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937f3ed-5655-44ed-9375-3dc4959f6a54",
   "metadata": {},
   "source": [
    "Other response quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48be4fe1-3dfa-4d9a-8ace-95f47bc31a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_metrics = {\n",
    "    \"Appropriateness\": \"Given the Context, evaluate from 1-5 the Response in terms of Appropriateness. Provide a single score and nothing else.\",\n",
    "    \"Relevance\": \"Given the Context, evaluate from 1-5 the Response in terms of Relevance. Provide a single score and nothing else.\",\n",
    "    \"Content Richness\": \"Given the Context, evaluate from 1-5 the Response in terms of Content Richness. Provide a single score and nothing else.\",\n",
    "    \"Grammatical Correctness\": \"Evaluate from 1-5 the Response in terms of Grammatical Correctness. Provide a single score and nothing else.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d26afd9-cab0-4297-9aa3-0efec1ae2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_to_score(message):\n",
    "    matches = re.findall(r\"\\b[1-5]\\b\", message)\n",
    "    if not matches:\n",
    "        return -1\n",
    "    return np.mean([float(m) for m in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0472c7b-ad6a-4e4e-8cf6-35566c801759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_quality(context, responses):\n",
    "    preds = {metric: [] for metric in gpt_metrics.keys()}\n",
    "    for res in tqdm(responses, desc=\"Responses\", leave=False):\n",
    "        for metric, prompt in gpt_metrics.items():\n",
    "            text_prompt = f\"Context:{context}\\nResponse:{res}\"\n",
    "            gpt_score = -1\n",
    "            score_backoff = 0\n",
    "            while gpt_score == -1 and score_backoff < 2:\n",
    "                responses = api.get_openai_chat_completion(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=20,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": prompt},\n",
    "                        {\"role\": \"user\", \"content\": text_prompt},\n",
    "                    ],\n",
    "                )\n",
    "                gpt_score = completion_to_score(responses[0])\n",
    "                score_backoff += 1\n",
    "            if gpt_score != -1:\n",
    "                preds[metric].append(gpt_score)\n",
    "            else:\n",
    "                preds[metric].append(3)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8dd8a9-c000-492f-a70a-988c281e27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 3/3 [00:09<00:00,  3.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Appropriateness': [4.0, 1.0, 2.0],\n",
       " 'Relevance': [4.0, 1.0, 2.0],\n",
       " 'Content Richness': [2.0, 1.0, 4.0],\n",
       " 'Grammatical Correctness': [5.0, 1.0, 4.0]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = [\"\"\"\n",
    "A: Hello!\n",
    "B: How are you doing?\n",
    "\"\"\"]\n",
    "responses = [\"\"\"\n",
    "I'm good. How about you?\n",
    "\"\"\", \"\"\"\n",
    "No.\n",
    "\"\"\", \"\"\"\n",
    "To be honest, not that good. My mother had a car crash yesterday.\n",
    "\"\"\"]\n",
    "\n",
    "get_response_quality(context, responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b02ac-95b1-49c9-a901-e89df1c369e9",
   "metadata": {},
   "source": [
    "Example evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ccec16e-8794-4bc1-9de2-f4fd1145a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 2/2 [00:04<00:00,  2.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'distinctiveness': 0.8,\n",
       " 'positive_constraints': [[1.0, 1.0], [1.0, 1.0]],\n",
       " 'negative_constraints': [[0.0, 0.0], [0.0, 0.0]],\n",
       " 'Appropriateness': [2.0, 4.0],\n",
       " 'Relevance': [2.0, 2.0],\n",
       " 'Content Richness': [2.0, 4.0],\n",
       " 'Grammatical Correctness': [2.0, 4.0]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "A: Hey brother, do you already have plans for the summer?\n",
    "\"\"\"\n",
    "responses = [\"I would like to invite you to dinner tonight.\", \"I would like to invite our entire family to my wedding.\"]\n",
    "\n",
    "\"\"\"\n",
    "Input: context, positive constraints, negative constraints and list of responses\n",
    "Output: Distinctiveness of responses, For each response: Positive satisfaction per sentence, Negative satisfaction per sentence, Quality measures\n",
    "\"\"\"\n",
    "def evaluate_responses(context, responses, positive_skills, negative_skills):\n",
    "    distinct_2 = calculate_distinct_n(responses)\n",
    "    positive_satisfaction = [detector.constraint_satisfaction(response, positive_skills) for response in responses]\n",
    "    negative_constraints = [detector.constraint_satisfaction(response, negative_skills) for response in responses]\n",
    "    qualities = get_response_quality(context, responses)\n",
    "    return {\"Distinctiveness\": distinct_2, \"positive_constraints\": positive_satisfaction, \"negative_constraints\": negative_constraints, **qualities}\n",
    "\n",
    "evaluate_responses(context, responses, [616, 617], [623, 624])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7c51b52-e3a6-421d-8f73-77c1613c9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_constraints(responses_list, skills_list):\n",
    "    return [[detector.constraint_satisfaction(response, skills) for response in responses] for responses, skills in zip(responses_list, skills_list)]\n",
    "\"\"\"\n",
    "Input: lists of response sets to evaluate\n",
    "Output: dict with list of evaluations\n",
    "\"\"\"\n",
    "def evaluate_responses_list(contexts, responses_list, positive_skills_list, negative_skills_list):\n",
    "    distinct_2 = [calculate_distinct_n(responses) for responses in responses_list]\n",
    "    positive_satisfaction = multiple_constraints(responses_list, positive_skills_list)\n",
    "    negative_constraints = multiple_constraints(responses_list, negative_skills_list)\n",
    "    qualities = [get_response_quality(context, responses) for context, responses in tqdm(zip(contexts, responses_list), total=len(contexts), desc=\"Contexts\")]\n",
    "    return {\"Distinctiveness\": distinct_2,\n",
    "            \"positive_constraints\": positive_satisfaction,\n",
    "            \"negative_constraints\": negative_constraints,\n",
    "            **{key: [d[key] for d in qualities] for key in qualities[0]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcd8d6f6-2efe-43da-910e-f471a1e10a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [\"\"\"A: Can I take the subway to get there?\n",
    "B: Yes, but that will probably take about half an hour. You should just take a taix.\n",
    "A: Won't that be expensive?\n",
    "B: \"\"\", \"\"\"A: Sir, I am very glad to tell that we have successfully registered the trademark for our new product. It is the time to think of some effective promoting strategies. We are beginning to get more attention from overseas.\n",
    "B: Well done, Fred. Do you know something useful for our promotion for our I-series?\n",
    "A: OK, Let me see. I suppose we must strengthen our promotion, because our brand is still new to some consumers. Maybe we should start our advertising program with our local and overseas distributors simultaneously, because they stand on a better position for selecting the best ways to advertise in market places. Besides, the advertisement fund can encourage them to spend more attention on advertising our products.\n",
    "B: \"\"\"]\n",
    "responses = [[\"Not necessarily, you can always share a ride with a friend or take a cheaper taxi service. Would you like me to look up some options for you?\", \"Yesterday I took the tram. Would you like me to look up the schedule?\"], [\"That sounds like a good plan. Would you be willing to lead this initiative and work closely with our distributors to ensure the success of our advertising campaign? And could you please report back to me with the progress and any feedback from the distributors?\", \"People will buy it anyways, I'm sure!\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "baedf98f-632a-4e29-a2da-88fa37be800d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b691b813654ffba860c94fe7afcafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Contexts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Responses:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Responses:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Distinctiveness': [0.8444444444444444, 1.0],\n",
       " 'positive_constraints': [[[0.0, 0.0, 0.5], [0.0, 0.0, 0.5]],\n",
       "  [[0.0, 0.0], [0.0, 0.0]]],\n",
       " 'negative_constraints': [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
       "  [[0.0, 0.0], [0.0, 0.0]]],\n",
       " 'Appropriateness': [[4.0, 2.0], [4.0, 2.0]],\n",
       " 'Relevance': [[4.0, 2.0], [4.0, 2.0]],\n",
       " 'Content Richness': [[4.0, 2.0], [4.0, 2.0]],\n",
       " 'Grammatical Correctness': [[5.0, 4.0], [4.0, 4.0]]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_responses_list(contexts, responses, [[616, 617, 621],[616, 617]], [[623, 624, 628],[623, 624]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d96c8-7a41-49ae-8ef9-98191ecccb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
