{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5342b3-6725-42d0-83e5-5db4cb1e1e8a",
   "metadata": {},
   "source": [
    "# Exp012: Train classifiers mainly from corpus examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f87740-f21a-48e3-bfc0-2ce119b2cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/dglandorf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import tensor, Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../source')\n",
    "import models\n",
    "import data\n",
    "import importlib\n",
    "#importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961585f3-8a6e-4e10-b0f3-e16a34a8eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:37<00:00,  9.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# load corpus sentences and prepare dataloader\n",
    "sentences = data.get_mixed_sentences(1000000) # get all sentences\n",
    "\n",
    "# initialize corpus to check against\n",
    "max_batches = 250\n",
    "batch_size = 64\n",
    "encoded_inputs = models.bert_tokenizer(sentences[:8*max_batches*batch_size], return_tensors='pt', max_length=64, padding='max_length', truncation=True)\n",
    "encoded_inputs['sentences'] = sentences[:8*max_batches*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa30f090-b507-4f11-bd5c-fc545d061952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataset\n",
    "output_path = '../data/annotated_corpus.json'\n",
    "instances = pd.DataFrame(columns=['#', 'sentence', 'positive']) if not os.path.exists(output_path) else pd.read_json(output_path)\n",
    "instances['positive'] = instances['positive'].astype(bool)\n",
    "\n",
    "egp_gpt = pd.read_json(\"../data/egp_gpt35.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87b1b7a-5687-4e04-88c2-2fae4eca2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation functions for instance dataset\n",
    "def get_positives(instances, nr):\n",
    "    return list(instances[(instances['#'] == nr) & instances['positive']]['sentence'])\n",
    "def get_negatives(instances, nr):\n",
    "    return list(instances[(instances['#'] == nr) & ~instances['positive']]['sentence'])\n",
    "def get_others(sentences, matches):\n",
    "    return list(set(sentences).difference(set(matches)))\n",
    "def add_to_instances(sentences, nr, positive=True):\n",
    "    global instances\n",
    "    if isinstance(sentences, list):\n",
    "        for sentence in sentences:\n",
    "            new_row = pd.DataFrame({'#': [nr], 'sentence': [sentence], 'positive': [positive]})\n",
    "            instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    else:\n",
    "        new_row = pd.DataFrame({'#': [nr], 'sentence': [sentences], 'positive': [positive]})\n",
    "        instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    instances.to_json(output_path)\n",
    "# data preparation\n",
    "def get_dataset(positives, negatives, others, tokenizer, max_len, others_ratio = 3):\n",
    "    unique_positive = list(set(positives)) # remove duplicates\n",
    "    unique_negative = list(set(negatives).difference(set(positives))) # remove duplicates and positives\n",
    "    num_rands = int(others_ratio * len(unique_negative))\n",
    "    random.shuffle(others)\n",
    "    sentences = unique_positive + unique_negative + others[:num_rands]\n",
    "    labels = [1] * len(unique_positive) + [0] * len(unique_negative) + [0] * len(others[:num_rands])\n",
    "    print(sum(labels) / len(labels))\n",
    "    return data.SentenceDataset(sentences, labels, tokenizer, max_len)\n",
    "# model training\n",
    "def get_trained_classifer(positive, negative, others, classifier=models.RuleDetector(models.bert_encoder), num_epochs=3, ratio=3):\n",
    "    dataset = get_dataset(positive, negative, others, models.bert_tokenizer, 64, ratio) \n",
    "    train_dataloader, val_dataloader = data.get_loaders(dataset)\n",
    "    models.train(classifier, train_dataloader, val_dataloader, num_epochs)\n",
    "    return classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a24689c-8004-4510-8cac-3e4dc0527c10",
   "metadata": {},
   "source": [
    "Find examples for would rules (616-638)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebc1b70-7706-4832-8f7c-9563d99b1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = 628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ade4eb-ecb4-4c8e-82d3-35b4e4a7c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(W|w)ould.*like\\?\"\n",
    "matches = [sentence for sentence in sentences if re.search(pattern, sentence)]\n",
    "random.shuffle(matches)\n",
    "candidates = iter(matches)\n",
    "threshold = min(len(matches), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5be73f1c-78d9-49a1-9c6e-c06a429d215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35 = egp_gpt[egp_gpt['#']==nr].iloc[0]\n",
    "matches = gpt35['augmented_examples'][:50]\n",
    "candidates = iter(matches)\n",
    "threshold = min(len(matches), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67436e5-e38b-4cea-a0ea-4c2a2986a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_pattern = r\"('d|would).*love\"\n",
    "anti_matches = [sentence for sentence in sentences if re.search(anti_pattern, sentence)]\n",
    "random.shuffle(anti_matches)\n",
    "candidates = iter(anti_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa879fc0-9e07-4d42-b23c-0af9d3647879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5501"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "364c4cae-fc3c-40a6-b207-2c72b41f52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = instances.iloc[:-103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "35dc6144-dc05-4c0c-9e58-7947ea22613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Based on his technical skills and innovative thinking, I would especially propose Andrew for the leadership position. 2\n",
      "Considering the economic situation, I would actually invest in real estate at this time. 2\n",
      "Despite the challenges, we would absolutely attend the event if given the opportunity. 2\n",
      "Given her expertise and dedication, she would gladly take on the new project. 2\n",
      "Knowing his attention to detail, I would strongly suggest Martin for the quality control role. 2\n",
      "Due to the company's ethical standards, they would easily reject the proposal. 2\n",
      "In light of recent developments, we would especially focus on customer satisfaction. 2\n",
      "Taking into account the market trends, I would actually diversify our investment portfolio. 2\n",
      "Knowing his love for adventure, he would absolutely enjoy the outdoor expedition. 2\n",
      "Given her experience and knowledge, she would gladly accept the teaching position. 2\n",
      "Reflecting on her talent and commitment, I would easily hire her for the creative role. 2\n",
      "Based on the team’s performance, I would especially reward them for their hard work. 2\n",
      "Considering the project requirements, we would actually meet the deadline. 2\n",
      "Despite the setbacks, we would absolutely overcome the challenges. 2\n",
      "Given the circumstances, I would strongly advise reconsidering the strategy. 2\n",
      "Taking into account the global impact, we would especially prioritize environmental initiatives. 2\n",
      "Reflecting on her talent and dedication, I would actually promote her to a managerial role. 2\n",
      "Considering her positivity and energy, she would gladly take on the leadership role. 2\n",
      "Based on the available resources, we would absolutely execute the plan. 2\n",
      "Knowing his resilience and determination, I would easily bet on his success. 2\n",
      "Despite the risks, we would strongly recommend the new marketing campaign. 2\n",
      "Given her adaptability, she would absolutely thrive in the dynamic work environment. 2\n",
      "Considering the potential outcomes, I would eagerly support the proposed changes. 2\n",
      "Based on his expertise and vision, I would easily entrust him with the project. 2\n",
      "Reflecting on the feedback, we would absolutely improve our customer service. 2\n",
      "I would actually appreciate it if you could complete the report by the end of the day. 2\n",
      "Even though it's a difficult decision, I would especially like you to consider all the options before making a choice. 2\n",
      "If you're feeling better today, I would absolutely love to go for a walk in the park. 2\n",
      "He would gladly accept the promotion if it were offered to him. 2\n",
      "She would strongly argue that the company needs to invest in new technology for better productivity. c\n"
     ]
    }
   ],
   "source": [
    "while 1==1: # len(get_positives(instances, nr)) < 1 * threshold or len(get_negatives(instances, nr)) < 2 * threshold:\n",
    "    if len(get_positives(instances, nr)) == 50: print(\"** REACHED 50 POSITIVES **\")\n",
    "    try:\n",
    "        candidate = next(candidates) \n",
    "    except StopIteration:\n",
    "        print(\"No candidates left.\")\n",
    "        break\n",
    "    if candidate in list(instances[instances['#'] == nr]['sentence']): continue\n",
    "    user_response = input(f\"{candidate}\")\n",
    "    if user_response == \"c\": break\n",
    "    if user_response == \"del\": \n",
    "        instances = instances.iloc[:-1]\n",
    "        continue\n",
    "    new_row = pd.DataFrame({'#': [nr], 'sentence': [candidate], 'positive': [True if user_response == '2' else False]})\n",
    "    instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    instances.to_json(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "febdfd34-a456-4792-8c04-b2b8e4a0d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 123, Negative: 365\n"
     ]
    }
   ],
   "source": [
    "print(f'Positive: {len(get_positives(instances, nr))}, Negative: {len(get_negatives(instances, nr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ee96c2a-4e83-4e9a-b990-612b2741fa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How could you go without me for all of those years.',\n",
       " 'Jórlaug works OK, as do Obba, Sigurfljóð, Úranía and – should you choose – Vagna.',\n",
       " 'Hi, taxi.Could you take me to the financial street, please',\n",
       " \"Well, I don't like climbing many stairs when there is a power cut.\",\n",
       " 'It does seem like a fun alternative to other dating activities!',\n",
       " 'I think my girls liked them because of the bears - they are both big animal fans.',\n",
       " 'More like a dance club but not quite sure how to get started.',\n",
       " \"I think you ' ll like it if you give it a chance.\",\n",
       " 'I like redheaded girls so much.',\n",
       " 'The girl coughed the water up almost immediately, and just like that, it was over.',\n",
       " \"It's frustrating that they feel the need to monitor what we do so closely instead of judging us based on our task performance, like most companies do these days.\",\n",
       " 'As many as you like, sir.',\n",
       " 'We would like to start you off at 2, 000 yuan a month, excluding bonus and overtime pay.',\n",
       " 'I would like to ask if those four days may be taken in lieu of the extra working hours I put in during the two weekends of the Chicago International Management Conference last November.',\n",
       " 'I would like to do something exciting like that.',\n",
       " 'I really like Miami, Ive been there many times and would like to move there some day.',\n",
       " 'Is there anything you would like to know, I have quite a good amount of knowledge about cats.',\n",
       " 'I would like the two clothes washed.',\n",
       " 'Well, I would like to book a single room.',\n",
       " 'If you had to choose between taking a salary cut and not having free coffee versus being let go, most employees would likely take the former.',\n",
       " 'We will have more available in a week if you would like to wait that long.',\n",
       " 'I would like to become  a vegan soon.',\n",
       " 'Yes, I would like to have a suit made to measure.',\n",
       " 'I would like to learn the history of yoga and how it came to be.',\n",
       " 'I would like to talk to you, if you have time.',\n",
       " 'I would like you see it.',\n",
       " 'Obviously I look for improvement as we go along, but I would like you to do your best from the beginning.',\n",
       " 'I would like you to meet my family.',\n",
       " 'Next Monday is my birthday, and I would like you to attend my party.',\n",
       " 'We would like you to stop by again so we can show you some more problems that have come up with our apartment.',\n",
       " 'I would like you to be my lawyer.',\n",
       " 'I would like you to fix the problem.',\n",
       " 'I would like you to give me a different hair style.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent for sent in get_negatives(instances, 621) if not \"?\" in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d145accc-1c71-4801-aa4e-c1823f0d0d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18385650224215247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:01<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2258114060934852\n",
      "Accuracy: 0.9701492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:01<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1526809260249138\n",
      "Accuracy: 0.9701492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:01<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.12813870477325776\n",
      "Accuracy: 0.9850746268656716\n"
     ]
    }
   ],
   "source": [
    "classifier = get_trained_classifer(get_positives(instances, nr), get_negatives(instances, nr), get_others(sentences, matches), num_epochs=3, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "593b6eff-a437-406d-8241-2dbd3416d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0331]), ['would'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.probe_model(classifier, 'I would want you to')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d9cf3-81df-4abc-a339-67be270a71ee",
   "metadata": {},
   "source": [
    "Check on entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b973cfbb-0cca-441d-9c55-e9b6b5e3aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████▎                                                                                            | 250/2000 [00:40<04:45,  6.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# shuffle inputs\n",
    "shuffled_index = np.random.permutation(encoded_inputs['input_ids'].size(0))\n",
    "for key, value in encoded_inputs.items():\n",
    "    encoded_inputs[key] = value[shuffled_index] if isinstance(value, Tensor) else [value[i] for i in shuffled_index]\n",
    "\n",
    "corpus_dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'])\n",
    "corpus_dataloader = DataLoader(corpus_dataset, batch_size=batch_size, shuffle=False)\n",
    "scores, tokens = models.score_corpus(classifier, corpus_dataloader, max_positive=250, max_batches=250, threshold=0.5)\n",
    "results = list(zip(scores, tokens, encoded_inputs['sentences'][:len(scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db88ffa1-21bc-4c3e-a1a6-36cee41abb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anne, would you please come in for a while?',\n",
       " 'Would you mind taking a look at the layout?',\n",
       " 'Would you still want full coverage?',\n",
       " 'Would Dr.Black be able to see me at 9:00 a. m. tomorrow?',\n",
       " 'Why would the person who told have problems with the law?',\n",
       " 'Would you mind telling me the purpose of your visit to the U. K.?',\n",
       " 'Would you consider an offer of $ 56,000 per year?',\n",
       " 'Would you mind speaking slowly?',\n",
       " 'Why would the officer lie?',\n",
       " \"If I don't pay my taxes, would the tax officials discover it?\",\n",
       " 'Would you mind if I ask some personal questions?',\n",
       " 'Would you please let the next applicant come in on your way out?',\n",
       " 'Thanks.Would you do me another favor?',\n",
       " 'Would you please bring me the black suit?',\n",
       " 'What would you do to achieve that?',\n",
       " 'How would you make that pay?',\n",
       " 'Yes, would you please call me a taxi first?',\n",
       " 'Excuse me, would you get me some paper napkins?',\n",
       " 'Would you please send them to us by next Wednesday?',\n",
       " 'Would you please weight this letter for me?',\n",
       " 'Would you tell me where we often travel?',\n",
       " \"Wouldn't the owners have told me about any problems?\",\n",
       " 'Would you allow me to drive your car?',\n",
       " 'Would that okay with you?',\n",
       " 'Would Friday morning be alright?',\n",
       " 'Would you able to pick him out of a line-up?',\n",
       " 'Would you mind telling me the purpose of your visit to the U. K. ?',\n",
       " 'How many rooms would it have?',\n",
       " 'Honey, would you marry me?',\n",
       " 'If you were choosing a person for this job, what kind of individual would you select?',\n",
       " 'Would you come with me to supply?',\n",
       " 'Why would I open it?',\n",
       " 'Then, would you recommend any other nearby hotel?',\n",
       " 'Would you please help me with my baggage?',\n",
       " 'Would you please call them to reserve a table?',\n",
       " 'If you were assigned some work which you are not so interested, would you take it or not?',\n",
       " 'Would you please tell me about the Fortune magazine?',\n",
       " 'How much more would it cost?',\n",
       " 'Would you please tell me about your pay skill first?',\n",
       " 'How would your present boss describe you?',\n",
       " 'How much would you say?',\n",
       " 'How would you describe your relationship with our boss?',\n",
       " 'OK. Um, if you had to live in one place where would you live?',\n",
       " 'Would you go to the bookstore with me?',\n",
       " 'Would you rather stay home?',\n",
       " 'Sure.Where would you suggest?',\n",
       " 'which would you want to buy?',\n",
       " 'What would you rather have, samosas or poppadoms?',\n",
       " 'Would you mind holding?',\n",
       " 'Well, would you please come back fifteen minutes later?',\n",
       " 'What starting salary would you expect here?',\n",
       " 'Would you excuse me?',\n",
       " 'Then when would it be a good time for you?',\n",
       " 'Would you tell us the quantity you require so that we can work out the offers?',\n",
       " 'Oh, Would you do me a favor?',\n",
       " 'Fine.Would it be OK to look at the room?',\n",
       " 'Would you help me figure out what to do about the office party?',\n",
       " 'Which one would you prefer?',\n",
       " 'Why would you keep it?',\n",
       " \"That's all right.Would you have a cup of coffee?\",\n",
       " 'Well, what annual quantity would you suggest for the new agreement then?',\n",
       " 'Kara, would you be interested in going to dinner again this Friday?',\n",
       " 'Would you please wait this letter to see with the postages?',\n",
       " 'How mush would it cost if someone parks here for one hour and ten minutes?',\n",
       " 'Mr. Liu, would you care for another helping?',\n",
       " 'Would you sit here please?',\n",
       " 'Would you show it to me, please?',\n",
       " \"It wouldn't be worth the trouble in that case, would it?\",\n",
       " 'Well, what would you suggest?',\n",
       " 'Can you tell me what training you have had that would specifically relate to the cable television Industry?',\n",
       " 'Would you mind my keeping it for another week?',\n",
       " 'How would we manage it though?',\n",
       " 'Would you please let the next applicant come in on your way out?',\n",
       " 'Would 1 : OO p. m. be convenient?',\n",
       " 'Would you show me your ID, sir, please?',\n",
       " 'Would you be interested in seeing the audio-visual products?',\n",
       " 'Would you have time to go look at apartments with me?',\n",
       " 'Would you please bring us the check?',\n",
       " 'How many hours would you need me to work each week?',\n",
       " 'Which would you recommend?',\n",
       " 'While I am at it, would it be possible to switch paint colors?',\n",
       " 'Would you be able to pick him out of a line-up?',\n",
       " 'Then what price would be fair to you?',\n",
       " 'We are busy in preparing for the train.Would you please buy us some fruit?',\n",
       " 'Why would you worry about me?',\n",
       " 'What would your mom say if you told her you are going to get married?',\n",
       " 'Excuse me, would you please tell me where I can find a telephone?',\n",
       " 'Would you be interested in taking part in an interview?',\n",
       " 'Yes, that would be nice, would I have a tour guide to tour completely visit these places?',\n",
       " 'Would you show us the menu?',\n",
       " 'Can you come in the morning or would afternoon be best?',\n",
       " 'Why would I do that?',\n",
       " 'Would you mind some company?',\n",
       " 'Would you mind taking your feet off the table, Mike?',\n",
       " 'Why would I be?',\n",
       " 'Would you be interested in applying for the job?',\n",
       " 'Would that be Fixed or Current Deposit?',\n",
       " 'Would you have time to go look at apartments with me?',\n",
       " 'Would you tell me the rate per day for depositing my bag?',\n",
       " \"Would 9:00 o'clock tomorrow morning be alright?\",\n",
       " 'Would you please shorten the sleeves?',\n",
       " 'What would make this apartment better for you?',\n",
       " 'Would you tell us the quantity you want so that we can work out an offer?',\n",
       " 'Would you get some of that new cereal we saw advertised on TV?',\n",
       " 'What would you recommend?',\n",
       " 'How would people get to work?',\n",
       " 'would you lend me some wreckers',\n",
       " \"He's with someone right now, would you hold?\",\n",
       " 'Would you be interested in seeing the apartment?',\n",
       " 'Would you mind changing?',\n",
       " 'Would it be all right if I painted the walls a different color?',\n",
       " 'Which currency would you require?',\n",
       " 'Would you give me another favor?',\n",
       " 'Would you be looking at long-term or short-term?',\n",
       " 'What color would you prefer?',\n",
       " 'How long would I have to pay back the loan?']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "subset = [(score, token, sample) for score, token, sample in results if\n",
    "     score > threshold]\n",
    "subset_sentences = [sample for _, _, sample in subset if \"like\" in sample]\n",
    "subset_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56453dda-8532-435d-8c18-efb186a87b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2949640287769784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.10598782179030505\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.08268489519303496\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.05490157820961692\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.06297581778331236\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.04817179421132261\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#add_to_instances(gpt35['augmented_examples'][100:150], nr, True)\n",
    "#add_to_instances(random.sample(subset_sentences, 25), nr, False)\n",
    "add_to_instances(subset_sentences, nr, False)\n",
    "#add_to_instances(random.sample(get_positives(instances, 619), 50), nr, False)\n",
    "#add_to_instances(list(set(get_positives(instances, 621)).difference(get_negatives(instances, nr))), nr, False)\n",
    "classifier = get_trained_classifer(get_positives(instances, nr), get_negatives(instances, nr)[-200:], get_others(sentences, matches), num_epochs=5, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b8502bd-cc53-4798-be85-44591abb0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_classifier(classifier, nr, \"corpus_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15416eea-43f2-49f3-bd22-08bc15c999a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp =models.load_classifier(616, \"corpus_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeaad7c9-89c4-4a7e-9008-3fd0013d2d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1237]), ['would'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.probe_model(exp, \"Would you like to invite me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4c97d-f8df-4f4c-a8fd-ed23d75a353d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
