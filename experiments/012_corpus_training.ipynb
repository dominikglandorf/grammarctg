{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f87740-f21a-48e3-bfc0-2ce119b2cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 101] Network is\n",
      "[nltk_data]     unreachable>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import tensor, Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../source')\n",
    "import models\n",
    "import data\n",
    "import importlib\n",
    "#importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961585f3-8a6e-4e10-b0f3-e16a34a8eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 3/3 [00:32<00:00, 10.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# load corpus sentences and prepare dataloader\n",
    "sentences = data.get_mixed_sentences(1000000) # get all sentences\n",
    "sentences = list(set(sentences))\n",
    "\n",
    "# initialize corpus to check against\n",
    "max_batches = 250\n",
    "batch_size = 64\n",
    "encoded_inputs = models.bert_tokenizer(sentences[:8*max_batches*batch_size], return_tensors='pt', max_length=64, padding='max_length', truncation=True)\n",
    "encoded_inputs['sentences'] = sentences[:8*max_batches*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa30f090-b507-4f11-bd5c-fc545d061952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataset\n",
    "output_path = '../data/annotated_corpus.json'\n",
    "instances = pd.DataFrame(columns=['#', 'sentence', 'positive']) if not os.path.exists(output_path) else pd.read_json(output_path)\n",
    "instances['positive'] = instances['positive'].astype(bool)\n",
    "\n",
    "egp_gpt = pd.read_json(\"../data/egp_gpt35.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87b1b7a-5687-4e04-88c2-2fae4eca2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation functions for instance dataset\n",
    "def get_positives(instances, nr):\n",
    "    return list(instances[(instances['#'] == nr) & instances['positive']]['sentence'])\n",
    "def get_negatives(instances, nr):\n",
    "    return list(instances[(instances['#'] == nr) & ~instances['positive']]['sentence'])\n",
    "def get_others(sentences, matches):\n",
    "    return list(set(sentences).difference(set(matches)))\n",
    "def add_to_instances(sentences, nr, positive=True):\n",
    "    global instances\n",
    "    if isinstance(sentences, list):\n",
    "        for sentence in sentences:\n",
    "            new_row = pd.DataFrame({'#': [nr], 'sentence': [sentence], 'positive': [positive]})\n",
    "            instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    else:\n",
    "        new_row = pd.DataFrame({'#': [nr], 'sentence': [sentences], 'positive': [positive]})\n",
    "        instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    instances.to_json(output_path)\n",
    "# data preparation\n",
    "def get_dataset(positives, negatives, others, tokenizer, max_len, others_ratio = 3):\n",
    "    unique_positive = list(set(positives)) # remove duplicates\n",
    "    unique_negative = list(set(negatives).difference(set(positives))) # remove duplicates and positives\n",
    "    num_rands = int(others_ratio * len(unique_negative))\n",
    "    random.shuffle(others)\n",
    "    sentences = unique_positive + unique_negative + others[:num_rands]\n",
    "    labels = [1] * len(unique_positive) + [0] * len(unique_negative) + [0] * len(others[:num_rands])\n",
    "    print(sum(labels) / len(labels))\n",
    "    return data.SentenceDataset(sentences, labels, tokenizer, max_len)\n",
    "# model training\n",
    "def get_trained_classifer(positive, negative, others, classifier=models.RuleDetector(models.bert_encoder), num_epochs=3, ratio=3):\n",
    "    dataset = get_dataset(positive, negative, others, models.bert_tokenizer, 64, ratio) \n",
    "    train_dataloader, val_dataloader = data.get_loaders(dataset)\n",
    "    models.train(classifier, train_dataloader, val_dataloader, num_epochs)\n",
    "    return classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a24689c-8004-4510-8cac-3e4dc0527c10",
   "metadata": {},
   "source": [
    "Find examples for would rules (616-638)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1ebc1b70-7706-4832-8f7c-9563d99b1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = 636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "76ade4eb-ecb4-4c8e-82d3-35b4e4a7c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(ed|en|nt).*would\"\n",
    "matches = [sentence for sentence in sentences if re.search(pattern, sentence)]\n",
    "random.shuffle(matches)\n",
    "candidates = iter(matches)\n",
    "threshold = min(len(matches), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5be73f1c-78d9-49a1-9c6e-c06a429d215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35 = egp_gpt[egp_gpt['#']==nr].iloc[0]\n",
    "matches = gpt35['augmented_examples'][:50]\n",
    "matches = subset_sentences\n",
    "candidates = iter(matches)\n",
    "threshold = min(len(matches), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "a67436e5-e38b-4cea-a0ea-4c2a2986a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_pattern = r\"('d|would)\"\n",
    "anti_matches = [sentence for sentence in sentences if re.search(anti_pattern, sentence)]\n",
    "random.shuffle(anti_matches)\n",
    "candidates = iter(anti_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "35dc6144-dc05-4c0c-9e58-7947ea22613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** REACHED 50 POSITIVES **\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Because of the limitations on the speed of aircraft at the time, it would take many hours to make the trip; it was generally accepted that a pilot could not make it alone. 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** REACHED 50 POSITIVES **\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "They say that if you didn't have a monopoly, you wouldn't be able to do the things you do. 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** REACHED 50 POSITIVES **\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "They would be his friends. 2\n",
      "So the playing field would mostly be even. 2\n",
      "I was worried you would think it was too far to drive. 1\n",
      "Yes, it would be. 1\n",
      "But if our ambitions were so easy to achieve, we would soon get bored. 2\n",
      "Seeing how she handled it -- she would talk about it if people wanted to -- showed me this was meant to be. 2\n",
      "But they would just raise the price of the units to cover their costs. 1\n",
      "I knew he would win. 1\n",
      "I like those too, I just wish that they would release more songs c\n"
     ]
    }
   ],
   "source": [
    "while len(get_positives(instances, nr)) < 2 * threshold or len(get_negatives(instances, nr)) < 2 * threshold:\n",
    "    if len(get_positives(instances, nr)) == 50: print(\"** REACHED 50 POSITIVES **\")\n",
    "    try:\n",
    "        candidate = next(candidates) \n",
    "    except StopIteration:\n",
    "        print(\"No candidates left.\")\n",
    "        break\n",
    "    if candidate in list(instances[instances['#'] == nr]['sentence']): continue\n",
    "    user_response = input(f\"{candidate}\")\n",
    "    if user_response == \"c\": break\n",
    "    if user_response == \"del\": \n",
    "        instances = instances.iloc[:-1]\n",
    "        continue\n",
    "    new_row = pd.DataFrame({'#': [nr], 'sentence': [candidate], 'positive': [True if user_response == '2' else False]})\n",
    "    instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    instances.to_json(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "febdfd34-a456-4792-8c04-b2b8e4a0d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 50, Negative: 50\n"
     ]
    }
   ],
   "source": [
    "print(f'Positive: {len(get_positives(instances, nr))}, Negative: {len(get_negatives(instances, nr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d145accc-1c71-4801-aa4e-c1823f0d0d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 4/4 [00:00<00:00,  9.48it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.943656712770462\n",
      "Accuracy: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 4/4 [00:00<00:00, 11.93it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9839863628149033\n",
      "Accuracy: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 4/4 [00:00<00:00, 12.11it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2726943977177143\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 4/4 [00:00<00:00, 12.15it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.12760697212070227\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 4/4 [00:00<00:00, 12.07it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.17192151863127947\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = get_trained_classifer(get_positives(instances, nr), get_negatives(instances, nr), get_others(sentences, matches), num_epochs=5, ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "593b6eff-a437-406d-8241-2dbd3416d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6954]), ['would'])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.probe_model(classifier, \"If I could, I would play the piano.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d9cf3-81df-4abc-a339-67be270a71ee",
   "metadata": {},
   "source": [
    "Check on entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b973cfbb-0cca-441d-9c55-e9b6b5e3aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|▎| 250/1000 [00:39<01:58,  6.\n"
     ]
    }
   ],
   "source": [
    "# shuffle inputs\n",
    "shuffled_index = np.random.permutation(encoded_inputs['input_ids'].size(0))\n",
    "for key, value in encoded_inputs.items():\n",
    "    encoded_inputs[key] = value[shuffled_index] if isinstance(value, Tensor) else [value[i] for i in shuffled_index]\n",
    "\n",
    "corpus_dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'])\n",
    "corpus_dataloader = DataLoader(corpus_dataset, batch_size=batch_size, shuffle=False)\n",
    "scores, tokens = models.score_corpus(classifier, corpus_dataloader, max_positive=250, max_batches=250, threshold=0.5)\n",
    "results = list(zip(scores, tokens, encoded_inputs['sentences'][:len(scores)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "db88ffa1-21bc-4c3e-a1a6-36cee41abb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tomorrow she would ask someone else to help her.',\n",
       " 'She would check his text messages and calls.',\n",
       " 'I would take biology with Mr. Green.',\n",
       " 'She would be laughing one moment, and if I said something insensitive, she would start crying.',\n",
       " 'I had a coworker that would take her dogs to a seniors home every weekend.',\n",
       " 'People would see them and begin crying.',\n",
       " 'Every weekend Jeffrey and his best friend Chad would head to Santa Monica Beach, where they would surf big waves.',\n",
       " 'He remembers watching his favorite players on TV when he was young, and how his father would take him to see the Giants play at Candlestick Park.',\n",
       " \"It's so named because in the pavilion over there the great poet Bai Buyi of the Tang Dynasty would take a rest after drinking a little too much, and watch the moon over the lake.\",\n",
       " 'She would tell people he was a deadbeat dad when he would call to get me and she would refuse.',\n",
       " 'He sang the lead, so he would do the main melody.',\n",
       " 'He would look at it again.',\n",
       " \"I would draw and listen to the Australian children's group called Hi-5.\",\n",
       " 'Someone would throw it and another person would hit it with a stick',\n",
       " 'So in every city, I would go to, I would sign up for a gym for two weeks or one month and you always meet people there.']"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "subset = [(score, token, sample) for score, token, sample in results if\n",
    "     score > threshold if \"would\" in sample]\n",
    "subset_sentences = [sample for _, _, sample in subset]\n",
    "subset_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "56453dda-8532-435d-8c18-efb186a87b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38817480719794345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 10/10 [00:00<00:00, 10.98i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.28319564908742906\n",
      "Accuracy: 0.9871794871794872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 10/10 [00:00<00:00, 12.14i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.21335369497537612\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 10/10 [00:00<00:00, 12.08i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.16749295704066752\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 10/10 [00:00<00:00, 12.14i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.14245141297578812\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 10/10 [00:00<00:00, 12.13i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.11716953404247761\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "add_to_instances(gpt35['augmented_examples'][100:150], nr, True)\n",
    "#add_to_instances(subset_sentences, nr, False)\n",
    "add_to_instances(get_positives(instances, 634), nr, False)\n",
    "classifier = get_trained_classifer(get_positives(instances, nr), get_negatives(instances, nr), get_others(sentences, matches), num_epochs=5, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "1b8502bd-cc53-4798-be85-44591abb0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_classifier(classifier, nr, \"corpus_training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
