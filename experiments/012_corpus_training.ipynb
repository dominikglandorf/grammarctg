{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f87740-f21a-48e3-bfc0-2ce119b2cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/dglandorf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../source')\n",
    "import models\n",
    "import data\n",
    "import importlib\n",
    "#importlib.reload(data)\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961585f3-8a6e-4e10-b0f3-e16a34a8eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:29<00:00,  9.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# load corpus sentences and prepare dataloader\n",
    "sentences = data.get_mixed_sentences(1000000) # get all sentences\n",
    "sentences = list(set(sentences))\n",
    "\n",
    "# initialize corpus to check against\n",
    "max_batches = 250\n",
    "batch_size = 64\n",
    "random.shuffle(sentences)\n",
    "encoded_inputs = models.bert_tokenizer(sentences[:4*max_batches*batch_size], return_tensors='pt', max_length=64, padding='max_length', truncation=True)\n",
    "corpus_dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'])\n",
    "corpus_dataloader = DataLoader(corpus_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa30f090-b507-4f11-bd5c-fc545d061952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataset\n",
    "output_path = '../data/annotated_corpus.json'\n",
    "instances = pd.DataFrame(columns=['#', 'sentence', 'positive']) if not os.path.exists(output_path) else pd.read_json(output_path)\n",
    "instances['positive'] = instances['positive'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87b1b7a-5687-4e04-88c2-2fae4eca2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation functions for instance dataset\n",
    "def get_positives(instances, nr):\n",
    "    return list(instances[(instances['#'] == nr) & instances['positive']]['sentence'])\n",
    "def get_negatives(instances, nr):\n",
    "    return list(instances[(instances['#'] == nr) & ~instances['positive']]['sentence'])\n",
    "def get_others(sentences, matches):\n",
    "    return list(set(sentences).difference(set(matches)))\n",
    "def add_to_instances(sentences, nr, positive=True):\n",
    "    global instances\n",
    "    if isinstance(sentences, list):\n",
    "        for sentence in sentences:\n",
    "            new_row = pd.DataFrame({'#': [nr], 'sentence': [sentence], 'positive': [positive]})\n",
    "            instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    else:\n",
    "        new_row = pd.DataFrame({'#': [nr], 'sentence': [sentences], 'positive': [positive]})\n",
    "        instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    instances.to_json(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e24f82-7b47-498f-a68c-80c1d4f6b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(positives, negatives, others, tokenizer, max_len, others_ratio = 3, max_positive_examples=500):\n",
    "    unique_positive = list(set(positives)) # remove duplicates\n",
    "    unique_negative = list(set(negatives).difference(set(positives))) # remove duplicates and positives\n",
    "    \n",
    "    sentences = unique_positive\n",
    "    labels = [1] * len(sentences)\n",
    "    sentences += unique_negative\n",
    "    labels += [0] * len(unique_negative)\n",
    "    num_rands = int(others_ratio * len(unique_negative))\n",
    "    sentences += others[:num_rands]\n",
    "    labels += [0] * num_rands\n",
    "    return data.SentenceDataset(sentences, labels, tokenizer, max_len)\n",
    "\n",
    "def get_trained_classifer(positive, negative, others, classifier=models.RuleDetector(models.bert_encoder), num_epochs=3):\n",
    "    dataset = get_dataset(positive, negative, others, models.bert_tokenizer, 64) \n",
    "    train_dataloader, val_dataloader = data.get_loaders(dataset)\n",
    "    models.train(classifier, train_dataloader, val_dataloader, num_epochs)\n",
    "    return classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a24689c-8004-4510-8cac-3e4dc0527c10",
   "metadata": {},
   "source": [
    "Find examples for would rules (616-638)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ebc1b70-7706-4832-8f7c-9563d99b1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = 627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ade4eb-ecb4-4c8e-82d3-35b4e4a7c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(would).*(n't|not).*(have).*\"\n",
    "matches = [sentence for sentence in sentences if re.search(pattern, sentence)]\n",
    "random.shuffle(matches)\n",
    "candidates = iter(matches)\n",
    "threshold = min(len(matches), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a67436e5-e38b-4cea-a0ea-4c2a2986a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_pattern = r\"(W|w)(ould).*(have).*(ed|en|id|ght) \"\n",
    "anti_matches = [sentence for sentence in sentences if re.search(anti_pattern, sentence)]\n",
    "random.shuffle(anti_matches)\n",
    "candidates = iter(anti_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "04da92d5-317f-496d-b364-2edaba10893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The EPA would know best, although they have been hindered this presidency. 1\n",
      "Would you have wanted them to adopt another child? 1\n",
      "i would loved to have and  listen to Katy Perry in the shower, but no, i do not 1\n",
      "I would have never imagined they come from persia, i love eating them specially in salads 1\n",
      "I would have loved some pork chops off the grill but my husband doesn't like pork chops not even the leaner piece cuts. 1\n",
      "I would have respected Al Gore a bit more if he hadn't tried to make this a film about himself as well. 1\n",
      "The next change would have been to put those words into sentences, similar to the 'protolanguage' children use when they first learn to speak. 1\n",
      "But I think it would have been wiser, far wiser, for the administration to have notified, certainly the leadership of Congress in the interest of having good relations. 1\n",
      "I would never have guessed that many people wore them! 1\n",
      "Wow, who would have thought an Arkansas company would get so big! 1\n",
      "That would have been boring! 1\n",
      "He dismisses the notion that the BBM curfew urged by some MPs would have stopped the looting. 1\n",
      "I would have thought it would be around longer, but then again, online hasn't existed that long! 1\n",
      "Well, I hadn't got any of the right qualifications, and it would have taken me two years to get qualified and I certainly didn't want to go back to formal education again. 1\n"
     ]
    }
   ],
   "source": [
    "while len(get_positives(instances, nr)) < threshold or len(get_negatives(instances, nr)) < 1.5 * threshold:\n",
    "    if len(get_positives(instances, nr)) == 50: print(\"** REACHED 50 POSITIVES **\")\n",
    "    try:\n",
    "        candidate = next(candidates) \n",
    "    except StopIteration:\n",
    "        print(\"No candidates left.\")\n",
    "        break\n",
    "    if candidate in list(instances[instances['#'] == nr]['sentence']): continue\n",
    "    user_response = input(f\"{candidate}\")\n",
    "    if user_response == \"c\": break\n",
    "    new_row = pd.DataFrame({'#': [nr], 'sentence': [candidate], 'positive': [True if user_response == '2' else False]})\n",
    "    instances = pd.concat([instances, new_row], ignore_index=True)\n",
    "    instances.to_json(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b1842c8f-6a86-4952-9ccf-ede5bae83d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>sentence</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>616</td>\n",
       "      <td>I would like to go there and pick one up too.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>616</td>\n",
       "      <td>I would like to see cute pandas, too.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>616</td>\n",
       "      <td>One more thing, we'd like you to quote us on C...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>616</td>\n",
       "      <td>I'd like to invite you and your photographic t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>616</td>\n",
       "      <td>Maybe he would like to play with us.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>627</td>\n",
       "      <td>Besides you wouldn't have to do much preparati...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>627</td>\n",
       "      <td>I would not have thought that.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>627</td>\n",
       "      <td>I would, but I don't have any in my tackle box.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>627</td>\n",
       "      <td>I really shouldn't have given her so much candy.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>627</td>\n",
       "      <td>They should not have an issue.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        #                                           sentence  positive\n",
       "0     616      I would like to go there and pick one up too.      True\n",
       "1     616              I would like to see cute pandas, too.      True\n",
       "2     616  One more thing, we'd like you to quote us on C...      True\n",
       "3     616  I'd like to invite you and your photographic t...      True\n",
       "4     616               Maybe he would like to play with us.      True\n",
       "...   ...                                                ...       ...\n",
       "2140  627  Besides you wouldn't have to do much preparati...     False\n",
       "2141  627                     I would not have thought that.      True\n",
       "2142  627    I would, but I don't have any in my tackle box.     False\n",
       "2143  627   I really shouldn't have given her so much candy.     False\n",
       "2144  627                     They should not have an issue.     False\n",
       "\n",
       "[2145 rows x 3 columns]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the last entry\n",
    "instances = instances.iloc[:-1]\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febdfd34-a456-4792-8c04-b2b8e4a0d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 55, Negative: 135\n"
     ]
    }
   ],
   "source": [
    "print(f'Positive: {len(get_positives(instances, nr))}, Negative: {len(get_negatives(instances, nr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d145accc-1c71-4801-aa4e-c1823f0d0d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6508052984873454\n",
      "Accuracy: 0.8956521739130435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.37286275029182436\n",
      "Accuracy: 0.9043478260869565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.23663161943356195\n",
      "Accuracy: 0.9043478260869565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1766846348841985\n",
      "Accuracy: 0.9652173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.13269841820001602\n",
      "Accuracy: 0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "classifier = get_trained_classifer(get_positives(instances, nr), get_negatives(instances, nr), get_others(sentences, matches), num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593b6eff-a437-406d-8241-2dbd3416d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7191]), ['have'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.probe_model(classifier, \"I wouldn't have guessed that.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d9cf3-81df-4abc-a339-67be270a71ee",
   "metadata": {},
   "source": [
    "Check on entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b973cfbb-0cca-441d-9c55-e9b6b5e3aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:40<00:00,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "scores, tokens = models.score_corpus(classifier, corpus_dataloader, max_positive=250, max_batches=500, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "db88ffa1-21bc-4c3e-a1a6-36cee41abb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5522863268852234,\n",
       "  'other',\n",
       "  \"On any other day, it would cost me a fortune, but it ' s on special offer today.\"),\n",
       " (0.5168756246566772, 'have', 'Thats more than I would have thought.'),\n",
       " (0.7443615794181824,\n",
       "  'have',\n",
       "  'I would not have thought about forests, that is interesting.'),\n",
       " (0.9253101944923401,\n",
       "  'otherwise',\n",
       "  'The Internet has connected people around the world that would never have been able to meet otherwise.')]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitelist = []\n",
    "threshold = 0.5\n",
    "\n",
    "[(score, token, sample) for score, token, sample in zip(scores, tokens, list(sentences)[:len(scores)]) if\n",
    "     score > threshold and not token in whitelist ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "e90a76e1-313e-4d87-a28e-ea826aa7fb67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"If I had to guess, I'd say the Miss Universe pageant is probably the biggest.\", \"If I were you, I'd just sleep, read a book, or watch TV.\", \"If I were you I'd check the bus schedule.\"]\n"
     ]
    }
   ],
   "source": [
    "false_pos = [sample for score, token, sample in zip(scores, tokens, list(sentences)[:len(scores)]) if\n",
    "     score > threshold and not token in whitelist and not \"would\" in sample]\n",
    "print(false_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "56453dda-8532-435d-8c18-efb186a87b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.11018610124786694\n",
      "Accuracy: 0.9739130434782609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.09457445945590734\n",
      "Accuracy: 0.9652173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0772305446366469\n",
      "Accuracy: 0.9826086956521739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.07244106183449427\n",
      "Accuracy: 0.9652173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:01<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.05815803979833921\n",
      "Accuracy: 0.991304347826087\n"
     ]
    }
   ],
   "source": [
    "add_to_instances(get_positives(instances, 626), nr, False)\n",
    "classifier = get_trained_classifer(get_positives(instances, nr), get_negatives(instances, nr), get_others(sentences, matches), num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1b8502bd-cc53-4798-be85-44591abb0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save_classifier(classifier, nr, \"corpus_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd0ca4-43d4-481b-bc30-b580991c8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
